<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Agentic Functional Programming in Rust</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="A pedagogical guide inspired by the Red Book and Rust resources.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="chapter_1_agentic_foundations.html">Agentic Introduction</a></li><li class="chapter-item expanded affix "><a href="chapter_2_getting_started.html">Getting Started</a></li><li class="chapter-item expanded affix "><a href="chapter_3_functional_data_structures.html">Functional Data Structures</a></li><li class="chapter-item expanded affix "><a href="chapter_4_handling_errors.html">Handling Errors</a></li><li class="chapter-item expanded affix "><a href="chapter_5_strictness_and_laziness.html">Strictness and Laziness</a></li><li class="chapter-item expanded affix "><a href="chapter_6_purely_functional_state.html">Purely Functional State</a></li><li class="chapter-item expanded affix "><a href="chapter_7_purely_functional_parallelism.html">Purely Functional Parallelism</a></li><li class="chapter-item expanded affix "><a href="chapter_8_property_based_testing.html">Property-Based Testing</a></li><li class="chapter-item expanded affix "><a href="chapter_9_parser_combinators.html">Parser Combinators</a></li><li class="chapter-item expanded affix "><a href="chapter_10_monoids.html">Monoids</a></li><li class="chapter-item expanded affix "><a href="chapter_11_monads.html">Monads</a></li><li class="chapter-item expanded affix "><a href="chapter_12_applicative.html">Applicative and Traversable</a></li><li class="chapter-item expanded affix "><a href="chapter_13_effects.html">External Effects and I/O</a></li><li class="chapter-item expanded affix "><a href="chapter_14_local_effects.html">Local Effects and Mutable State</a></li><li class="chapter-item expanded affix "><a href="chapter_15_streaming.html">Stream Processing</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Agentic Functional Programming in Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-1-what-is-functional-programming"><a class="header" href="#chapter-1-what-is-functional-programming">Chapter 1: What is functional programming?</a></h1>
<blockquote>
<p><em>Last Updated: 2025-12-29</em></p>
</blockquote>
<p>Functional programming (FP) is based on a simple premise with far-reaching implications: we construct our programs using only pure functions—in other words, functions that have no side effects. What are side effects? A function has a side effect if it does something other than simply return a result, for example:</p>
<ul>
<li>Modifying a variable</li>
<li>Modifying a data structure in place</li>
<li>Setting a field on an object</li>
<li>Throwing an exception or halting with an error</li>
<li>Printing to the console or reading user input</li>
<li>Reading from or writing to a file</li>
<li>Drawing on the screen</li>
<li><strong>Calling an external API (like an LLM or Database)</strong></li>
</ul>
<p>We’ll provide a more precise definition of side effects later in this chapter, but consider what programming would be like without the ability to do these things. It may be difficult to imagine. How is it even possible to write useful Agentic workflows at all? If we can't call APIs or update memory, how do our Agents do anything?</p>
<p>The answer is that functional programming is a restriction on <em>how</em> we write programs, but not on <em>what</em> programs we can express. Over the course of this book, we’ll learn how to express all of our Agentic workflows without side effects, and that includes programs that perform I/O, handle errors, and manage context. We’ll learn how following the discipline of FP is tremendously beneficial because of the increase in modularity that we gain from programming with pure functions (which we can think of as <strong>Deterministic Tools</strong>). Because of their modularity, these tools are easier to test, reuse, parallelize, generalize, and reason about. Furthermore, pure functions are much less prone to bugs (or hallucinations in logic).</p>
<p>In this chapter, we’ll look at a simple program with side effects and demonstrate some of the benefits of FP by removing these side effects. We’ll also discuss the benefits of FP more generally and define two important concepts—referential transparency and the substitution model.</p>
<h2 id="11-the-benefits-of-fp-a-simple-example"><a class="header" href="#11-the-benefits-of-fp-a-simple-example">1.1 The benefits of FP: a simple example</a></h2>
<p>Let’s look at an example that demonstrates some of the benefits of programming with pure functions. The point here is just to illustrate some basic ideas that we’ll return to throughout this book. This will also be your first exposure to Rust's syntax if you are new to the language.</p>
<h3 id="111-a-program-with-side-effects"><a class="header" href="#111-a-program-with-side-effects">1.1.1 A program with side effects</a></h3>
<p>Suppose we’re implementing a client to interact with an Large Language Model (LLM). We want to generate text completions and bill our users for the tokens they consume. We’ll begin with a Rust program that uses side effects in its implementation (also called an impure program).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone, Copy)] struct Completion { tokens: i32 }
</span><span class="boring">impl Completion { fn new() -&gt; Self { Completion { tokens: 100 } } }
</span><span class="boring">struct BillingService;
</span><span class="boring">impl BillingService { fn charge_usage(&amp;mut self, _tokens: i32) {} }
</span>struct LLMClient;

impl LLMClient {
    fn generate_completion(&amp;self, billing: &amp;mut BillingService) -&gt; Completion {
        let response = Completion::new();
        billing.charge_usage(response.tokens);
        response
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let client = LLMClient;
</span><span class="boring">    let mut billing = BillingService;
</span><span class="boring">    let _ = client.generate_completion(&amp;mut billing);
</span><span class="boring">}</span></code></pre></pre>
<p>The line <code>billing.charge_usage(response.tokens)</code> is an example of a side effect. Charging for usage involves interaction with the outside world—suppose it requires contacting a database, updating a distributed quota system, or calling an external payment provider like Stripe.</p>
<p>But our function merely returns a <code>Completion</code> (the text response) and these other actions are happening on the side, hence the term “side effect.”</p>
<p>As a result of this side effect, the code is difficult to test. We don’t want our unit tests to actually contact the billing system and charge real money! This lack of testability is suggesting a design change: arguably, <code>LLMClient</code> shouldn’t have any knowledge baked into it about how to contact the billing system, nor should it have knowledge of how to persist transaction records. We can make the code more modular and testable by letting <code>LLMClient</code> be ignorant of these concerns and passing a <code>Billing</code> object into <code>generate_completion</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone, Copy)] struct Completion { tokens: i32 }
</span><span class="boring">impl Completion { fn new() -&gt; Self { Completion { tokens: 100 } } }
</span><span class="boring">struct BillingService;
</span><span class="boring">trait Billing { fn charge_usage(&amp;mut self, tokens: i32); }
</span><span class="boring">struct MockBilling;
</span><span class="boring">impl Billing for MockBilling { fn charge_usage(&amp;mut self, _tokens: i32) {} }
</span>struct LLMClient;

impl LLMClient {
    fn generate_completion(&amp;self, billing: &amp;mut dyn Billing) -&gt; Completion {
        let response = Completion::new();
        billing.charge_usage(response.tokens);
        response
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let client = LLMClient;
</span><span class="boring">    let mut mock = MockBilling;
</span><span class="boring">    let _ = client.generate_completion(&amp;mut mock);
</span><span class="boring">}</span></code></pre></pre>
<p>Though side effects still occur when we call <code>billing.charge_usage</code>, we have at least regained some testability. <code>Billing</code> can be a trait (interface), and we can write a mock implementation of this trait that is suitable for testing. But that isn’t ideal either. We’re forced to make <code>Billing</code> a trait, when a concrete struct may have been fine otherwise, and any mock implementation will be awkward to use. For example, it might contain some internal state that we’ll have to inspect after the call to <code>generate_completion</code>, and our test will have to make sure this state has been appropriately modified (mutated) by the call.</p>
<p>Separate from the concern of testing, there’s another problem: it’s difficult to reuse <code>generate_completion</code>. Suppose we want to implement a "Chain of Thought" workflow where we generate 12 intermediate reasoning steps. Ideally we could just reuse <code>generate_completion</code> for this, perhaps calling it 12 times in a loop. But as it is currently implemented, that will involve contacting the billing system 12 times! That adds significant latency and load to our billing infrastructure.</p>
<h3 id="112-a-functional-solution-removing-the-side-effects"><a class="header" href="#112-a-functional-solution-removing-the-side-effects">1.1.2 A functional solution: removing the side effects</a></h3>
<p>The functional solution is to eliminate side effects and have <code>generate_completion</code> return the usage cost as a value in addition to returning the <code>Completion</code>. The concerns of processing the cost by checking quotas, persisting records, and so on, will be handled elsewhere.</p>
<p>Here’s what a functional solution might look like in Rust:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone)] struct AccountId;
</span><span class="boring">#[derive(Clone, Copy)] struct Completion { tokens: i32 }
</span><span class="boring">impl Completion { fn new() -&gt; Self { Completion { tokens: 100 } } }
</span><span class="boring">struct TokenUsage { account: AccountId, tokens: i32 }
</span><span class="boring">impl TokenUsage { fn new(account: AccountId, tokens: i32) -&gt; Self { TokenUsage { account, tokens } } }
</span>struct LLMClient;

impl LLMClient {
    fn generate_completion(&amp;self, account: &amp;AccountId) -&gt; (Completion, TokenUsage) {
        let response = Completion::new();
        (response, TokenUsage::new(account.clone(), response.tokens))
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let client = LLMClient;
</span><span class="boring">    let account = AccountId;
</span><span class="boring">    let _ = client.generate_completion(&amp;account);
</span><span class="boring">}</span></code></pre></pre>
<p>Here we’ve separated the concern of <em>creating</em> a usage record from the <em>processing</em> of that record. The <code>generate_completion</code> function now returns a <code>TokenUsage</code> as a value along with the <code>Completion</code>. We’ll see shortly how this lets us reuse it more easily to generate multiple completions with a single transaction. But what is <code>TokenUsage</code>? It’s a data type we just invented containing an <code>AccountId</code> and an amount, equipped with a handy function, <code>combine</code>, for combining usage logs for the same Account:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(PartialEq, Clone)] struct AccountId;
</span>struct TokenUsage {
    account: AccountId,
    tokens: i32,
}

impl TokenUsage {
    fn combine(&amp;self, other: &amp;TokenUsage) -&gt; Result&lt;TokenUsage, String&gt; {
        if self.account == other.account {
            Ok(TokenUsage {
                account: self.account.clone(),
                tokens: self.tokens + other.tokens,
            })
        } else {
            Err("Can't combine usage for different accounts".to_string())
        }
    }
}
<span class="boring">fn main() {
</span><span class="boring">   let acc = AccountId;
</span><span class="boring">   let u1 = TokenUsage { account: acc.clone(), tokens: 50 };
</span><span class="boring">   let u2 = TokenUsage { account: acc, tokens: 150 };
</span><span class="boring">   assert!(u1.combine(&amp;u2).is_ok());
</span><span class="boring">}</span></code></pre></pre>
<p>Now let’s look at <code>batch_generate</code>, to implement the generation of <code>n</code> completions. Unlike before, this can now be implemented in terms of <code>generate_completion</code>, as we had hoped.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(PartialEq, Clone)] struct AccountId;
</span><span class="boring">#[derive(Clone, Copy)] struct Completion { tokens: i32 }
</span><span class="boring">impl Completion { fn new() -&gt; Self { Completion { tokens: 100 } } }
</span><span class="boring">#[derive(Clone)] struct TokenUsage { account: AccountId, tokens: i32 }
</span><span class="boring">impl TokenUsage { 
</span><span class="boring">   fn new(account: AccountId, tokens: i32) -&gt; Self { TokenUsage { account, tokens } } 
</span><span class="boring">   fn combine(&amp;self, other: &amp;TokenUsage) -&gt; Result&lt;TokenUsage, String&gt; { Ok(TokenUsage { account: self.account.clone(), tokens: self.tokens + other.tokens }) }
</span><span class="boring">}
</span><span class="boring">struct LLMClient;
</span>impl LLMClient {
<span class="boring">  fn generate_completion(&amp;self, account: &amp;AccountId) -&gt; (Completion, TokenUsage) { (Completion::new(), TokenUsage::new(account.clone(), 100)) }
</span>    fn batch_generate(&amp;self, account: &amp;AccountId, n: usize) -&gt; (Vec&lt;Completion&gt;, TokenUsage) {
        let results: Vec&lt;(Completion, TokenUsage)&gt; = (0..n)
            .map(|_| self.generate_completion(account))
            .collect();
        
        let (completions, usages): (Vec&lt;Completion&gt;, Vec&lt;TokenUsage&gt;) = results.into_iter().unzip();
        
        let total_usage = usages.into_iter()
            .reduce(|u1, u2| u1.combine(&amp;u2).unwrap())
            .unwrap_or(TokenUsage::new(account.clone(), 0));
            
        (completions, total_usage)
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let client = LLMClient;
</span><span class="boring">    let acc = AccountId;
</span><span class="boring">    let (_, usage) = client.batch_generate(&amp;acc, 12);
</span><span class="boring">    assert_eq!(usage.tokens, 1200);
</span><span class="boring">}</span></code></pre></pre>
<p>Overall, this solution is a marked improvement—we’re now able to reuse <code>generate_completion</code> directly to define the <code>batch_generate</code> function, and both functions are trivially testable without having to define complicated mock implementations of some <code>Billing</code> interface!</p>
<p>Making <code>TokenUsage</code> into a first-class value has other benefits we might not have anticipated: we can more easily assemble business logic for working with these usage logs. For instance, an Agent might run a complex multi-step workflow involving creating documents, researching, and coding. It might be nice if we could combine all the usage across these different tools into a single billable event. Since <code>TokenUsage</code> is first-class, we can write the following function to coalesce any same-account usage in a <code>Vec&lt;TokenUsage&gt;</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::collections::HashMap;
</span><span class="boring">#[derive(PartialEq, Eq, Clone, Hash)] struct AccountId;
</span><span class="boring">#[derive(Clone)] struct TokenUsage { account: AccountId, tokens: i32 }
</span><span class="boring">impl TokenUsage { fn combine(&amp;self, other: &amp;TokenUsage) -&gt; Result&lt;TokenUsage, String&gt; { Ok(TokenUsage { account: self.account.clone(), tokens: self.tokens + other.tokens }) } }
</span> 
fn coalesce_usage(logs: Vec&lt;TokenUsage&gt;) -&gt; Vec&lt;TokenUsage&gt; {
    // In a real Rust app, we might use itertools using a HashMap or sort first
    // Since we don't have itertools in pure std, we can implement it simply.
    
    let mut groups: HashMap&lt;AccountId, Vec&lt;TokenUsage&gt;&gt; = HashMap::new();
    for log in logs {
        groups.entry(log.account.clone()).or_default().push(log);
    }
    
    groups.values()
        .map(|list| list.iter().cloned().reduce(|u1, u2| u1.combine(&amp;u2).unwrap()).unwrap())
        .collect()
}
<span class="boring">fn main() {
</span><span class="boring">   let acc = AccountId;
</span><span class="boring">   let logs = vec![TokenUsage { account: acc.clone(), tokens: 10 }, TokenUsage { account: acc, tokens: 20 }];
</span><span class="boring">   let summary = coalesce_usage(logs);
</span><span class="boring">   assert_eq!(summary[0].tokens, 30);
</span><span class="boring">}</span></code></pre></pre>
<p>This sort of transformation can be applied to any function with side effects to push these effects to the outer layers of the program. Functional programmers often speak of implementing programs with a pure core and a thin layer on the outside that handles effects (I/O).</p>
<h2 id="12-exactly-what-is-a-pure-function"><a class="header" href="#12-exactly-what-is-a-pure-function">1.2 Exactly what is a (pure) function?</a></h2>
<p>We said earlier that FP means programming with pure functions, and a pure function is one that lacks side effects. In our discussion of the LLM example, we worked off an informal notion of side effects and purity. Here we’ll formalize this notion, to pinpoint more precisely what it means to program functionally (or "Agentically").</p>
<p>A function <code>f</code> with input type <code>A</code> and output type <code>B</code> (written in Rust as <code>fn(A) -&gt; B</code>) is a computation that relates every value <code>a</code> of type <code>A</code> to exactly one value <code>b</code> of type <code>B</code> such that <code>b</code> is determined solely by the value of <code>a</code>. Any changing state of an internal or external process is irrelevant to computing the result <code>f(a)</code>. For example, a function <code>int_to_string</code> having type <code>fn(i32) -&gt; String</code> will take every integer to a corresponding string. Furthermore, if it really is a function, it will do nothing else.</p>
<p>In other words, a function (or <strong>Deterministic Tool</strong>) has no observable effect on the execution of the program other than to compute a result given its inputs; we say that it has no side effects.</p>
<p>We can formalize this idea of pure functions using the concept of <strong>referential transparency (RT)</strong>. This is a property of expressions in general and not just functions. For the purposes of our discussion, consider an expression to be any part of a program that can be evaluated to a result. For example, <code>2 + 3</code> is an expression that applies the pure function <code>+</code> to the values <code>2</code> and <code>3</code>. This has no side effect. The evaluation of this expression results in the same value <code>5</code> every time. In fact, if we saw <code>2 + 3</code> in a program we could simply replace it with the value <code>5</code> and it wouldn’t change a thing about the meaning of our program.</p>
<p>This is all it means for an expression to be referentially transparent—in any program, the expression can be replaced by its result without changing the meaning of the program. And we say that a function is pure if calling it with RT arguments is also RT.</p>
<h2 id="13-referential-transparency-purity-and-the-substitution-model"><a class="header" href="#13-referential-transparency-purity-and-the-substitution-model">1.3 Referential transparency, purity, and the substitution model</a></h2>
<p>Let’s see how the definition of RT applies to our original <code>generate_completion</code> example:</p>
<pre><code class="language-rust ignore">fn generate_completion(&amp;self, billing: &amp;mut BillingService) -&gt; Completion {
    let response = Completion::new();
    billing.charge_usage(response.tokens);
    response
}</code></pre>
<p>Whatever the return type of <code>billing.charge_usage(...)</code> (perhaps it’s <code>()</code> unit), it’s discarded by <code>generate_completion</code>. Thus, the result of evaluating <code>generate_completion(my_account)</code> will be merely <code>response</code>. For <code>generate_completion</code> to be pure, by our definition of RT, it must be the case that <code>p(generate_completion(my_account))</code> behaves the same as <code>p(Completion::new())</code>, for any <code>p</code>.</p>
<p>This clearly doesn’t hold—the program <code>Completion::new()</code> doesn’t do anything, whereas <code>generate_completion(my_account)</code> will contact the billing system and charge real money. Already we have an observable difference between the two programs.</p>
<p>Referential transparency forces the invariant that everything a function does is represented by the value that it returns, according to the result type of the function. This constraint enables a simple and natural mode of reasoning about program evaluation called the <strong>substitution model</strong>. When expressions are referentially transparent, we can imagine that computation proceeds much like we’d solve an algebraic equation. We fully expand every part of an expression, replacing all variables with their referents, and then reduce it to its simplest form. At each step we replace a term with an equivalent one; computation proceeds by substituting equals for equals. In other words, RT enables equational reasoning about programs.</p>
<h2 id="14-summary"><a class="header" href="#14-summary">1.4 Summary</a></h2>
<p>In this chapter, we introduced functional programming and explained exactly what FP is and why you might use it. We illustrated some of the benefits of FP using a simple example. We also discussed referential transparency and the substitution model and talked about how FP enables simpler reasoning about programs and greater modularity.</p>
<p>In this book, you’ll learn the concepts and principles of FP as they apply to every level of Agentic programming, starting from the simplest of tasks and building on that foundation.</p>
<h2 id="15-references"><a class="header" href="#15-references">1.5 References</a></h2>
<ul>
<li><strong>Rust Book Ch 1 (Introduction)</strong>: <a href="https://doc.rust-lang.org/book/ch01-00-getting-started.html">The Rust Programming Language</a></li>
<li><strong>Rust By Example</strong>: <a href="https://doc.rust-lang.org/rust-by-example/index.html">Introduction</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-2-getting-started-with-functional-programming-in-rust"><a class="header" href="#chapter-2-getting-started-with-functional-programming-in-rust">Chapter 2: Getting started with functional programming in Rust</a></h1>
<p>In this chapter, we’ll begin learning how to write programs in the Rust language just by combining pure functions (Deterministic Tools). This chapter is mainly intended for those readers who are new to Rust, to functional programming, or both.</p>
<h2 id="21-introducing-rust-an-example"><a class="header" href="#21-introducing-rust-an-example">2.1 Introducing Rust: an example</a></h2>
<p>The following is a complete program listing in Rust. Our goal is just to introduce the Rust language and its syntax.</p>
<pre><pre class="playground"><code class="language-rust">// A comment!
/* Another comment */
/// A documentation comment

pub mod my_module {
    /// Pure function to calculate remaining tokens in a context window
    pub fn remaining_context(used: i32, limit: i32) -&gt; i32 {
        let remaining = limit - used;
        if remaining &lt; 0 {
            0
        } else {
            remaining
        }
    }

    pub fn format_status(used: i32) -&gt; String {
        format!("Context used: {}, Remaining: {}", used, remaining_context(used, 8192))
    }

    pub fn main() {
        println!("{}", format_status(4000));
    }
}
<span class="boring">fn main() {
</span><span class="boring">    my_module::main();
</span><span class="boring">}</span></code></pre></pre>
<p>We declare a module <code>my_module</code>. This is simply to give our code a place to live. Rust code is organized into modules (<code>mod</code>) and creates (structs, enums).</p>
<p>The <code>remaining_context</code> function is a pure function that takes two integers and returns the remaining capacity. Note the absence of an explicit <code>return</code> keyword. The value returned from a function is simply whatever value results from evaluating the last expression in the block.</p>
<h2 id="22-running-our-program"><a class="header" href="#22-running-our-program">2.2 Running our program</a></h2>
<p>The simplest way to run this is using <code>cargo</code>. If this were in <code>src/main.rs</code>, you could run:</p>
<pre><code class="language-sh">cargo run
</code></pre>
<h2 id="23-higher-order-functions-passing-functions-to-functions"><a class="header" href="#23-higher-order-functions-passing-functions-to-functions">2.3 Higher-order functions: passing functions to functions</a></h2>
<p>Functions are values. They can be assigned to variables, stored in data structures, and passed as arguments to functions.</p>
<h3 id="231-a-short-detour-writing-loops-functionally"><a class="header" href="#231-a-short-detour-writing-loops-functionally">2.3.1 A short detour: writing loops functionally</a></h3>
<p>First, let’s write <code>retry_backoff</code> to calculate the wait time (in ms) for the <code>n</code>th retry of a failed API call (simple factorial-style growth for demonstration):</p>
<pre><pre class="playground"><code class="language-rust">fn retry_backoff(n: i32) -&gt; i32 {
    fn go(n: i32, acc: i32) -&gt; i32 {
        if n &lt;= 0 {
            acc
        } else {
            go(n - 1, n * acc)
        }
    }
    go(n, 1)
}
<span class="boring">fn main() {
</span><span class="boring">    assert_eq!(retry_backoff(5), 120);
</span><span class="boring">}</span></code></pre></pre>
<p>The way we write loops functionally, without mutating a loop variable, is with a recursive function. Rust supports recursion, though it does not guarantee <strong>tail call elimination</strong> (TCO) in the same way Scala or Scheme might. For deep recursion (like an infinite agent loop), Rust programmers often use <code>loop</code>, <code>while</code>, or iterators to avoid blowing the stack. However, for the sake of learning FP concepts, we will use recursion here.</p>
<h3 id="exercise-21"><a class="header" href="#exercise-21">Exercise 2.1</a></h3>
<p>Write a recursive function to simulate a simplified Fibonacci-style token generation curve. The 0th and 1st steps produce 0 and 1 tokens respectively. The <code>n</code>th step produces the sum of the previous two.</p>
<pre><pre class="playground"><code class="language-rust">pub fn token_simulation(n: u32) -&gt; u32 {
    fn go(n: u32, prev: u32, curr: u32) -&gt; u32 {
        if n == 0 {
            prev
        } else {
            go(n - 1, curr, prev + curr)
        }
    }
    go(n, 0, 1)
}
<span class="boring">fn main() {
</span><span class="boring">    assert_eq!(token_simulation(0), 0);
</span><span class="boring">    assert_eq!(token_simulation(1), 1);
</span><span class="boring">    assert_eq!(token_simulation(5), 5);
</span><span class="boring">    assert_eq!(token_simulation(6), 8);
</span><span class="boring">}</span></code></pre></pre>
<h3 id="232-writing-our-first-higher-order-function"><a class="header" href="#232-writing-our-first-higher-order-function">2.3.2 Writing our first higher-order function</a></h3>
<p>We can generalize <code>format_status</code> and <code>format_backoff</code> to a single function <code>format_metric</code>:</p>
<pre><pre class="playground"><code class="language-rust">fn format_metric(name: &amp;str, n: i32, f: fn(i32) -&gt; i32) -&gt; String {
    format!("The {} for input {} is {}.", name, n, f(n))
}
<span class="boring">fn main() {
</span><span class="boring">    fn double(x: i32) -&gt; i32 { x * 2 }
</span><span class="boring">    println!("{}", format_metric("doubling", 21, double));
</span><span class="boring">}</span></code></pre></pre>
<p><code>f</code> is a function pointer or closure trait. Here we use <code>fn(i32) -&gt; i32</code>, which is a function pointer.</p>
<h2 id="24-polymorphic-functions-abstracting-over-types"><a class="header" href="#24-polymorphic-functions-abstracting-over-types">2.4 Polymorphic functions: abstracting over types</a></h2>
<p>We can write functions that work for any type.</p>
<h3 id="241-an-example-of-a-polymorphic-function"><a class="header" href="#241-an-example-of-a-polymorphic-function">2.4.1 An example of a polymorphic function</a></h3>
<p>Finding the first relevant Tool Call in a list of messages:</p>
<pre><pre class="playground"><code class="language-rust">fn find_first_tool&lt;A, F&gt;(items: &amp;[A], predicate: F) -&gt; Option&lt;usize&gt; 
where F: Fn(&amp;A) -&gt; bool {
    let mut n = 0;
    while n &lt; items.len() {
        if predicate(&amp;items[n]) {
            return Some(n);
        }
        n += 1;
    }
    None
}
<span class="boring">fn main() {
</span><span class="boring">    let tools = vec!["search", "calculator", "weather"];
</span><span class="boring">    assert_eq!(find_first_tool(&amp;tools, |x| *x == "calculator"), Some(1));
</span><span class="boring">}</span></code></pre></pre>
<p>Here, <code>A</code> is a generic type parameter. <code>F</code> is a generic type bounded by the <code>Fn</code> trait.</p>
<h3 id="exercise-22"><a class="header" href="#exercise-22">Exercise 2.2</a></h3>
<p>Implement <code>is_chronological</code>, which checks whether a slice of <code>Message</code>s <code>&amp;[A]</code> is sorted according to a given comparison function (e.g., timestamps).</p>
<pre><pre class="playground"><code class="language-rust">pub fn is_chronological&lt;A, F&gt;(messages: &amp;[A], ordered: F) -&gt; bool 
where F: Fn(&amp;A, &amp;A) -&gt; bool {
    let mut n = 0;
    while n + 1 &lt; messages.len() {
        if !ordered(&amp;messages[n], &amp;messages[n+1]) {
            return false;
        }
        n += 1;
    }
    true
}
<span class="boring">fn main() {
</span><span class="boring">    assert!(is_chronological(&amp;[1, 2, 3], |a, b| a &lt;= b));
</span><span class="boring">    assert!(!is_chronological(&amp;[1, 3, 2], |a, b| a &lt;= b));
</span><span class="boring">}</span></code></pre></pre>
<h2 id="25-following-types-to-implementations"><a class="header" href="#25-following-types-to-implementations">2.5 Following types to implementations</a></h2>
<h3 id="exercise-23-currying"><a class="header" href="#exercise-23-currying">Exercise 2.3 (Currying)</a></h3>
<p>Currying converts a function <code>f</code> of two arguments (e.g., a function taking <code>(SystemPrompt, UserQuery)</code>) into a function of one argument that partially applies the first (e.g., returns a function waiting for <code>UserQuery</code> with <code>SystemPrompt</code> baked in).</p>
<pre><pre class="playground"><code class="language-rust">pub fn curry&lt;A, B, C, F&gt;(f: F) -&gt; impl Fn(A) -&gt; Box&lt;dyn Fn(B) -&gt; C&gt;
where
    A: 'static + Clone,
    B: 'static,
    C: 'static,
    F: Fn(A, B) -&gt; C + 'static + Clone,
{
    move |a: A| {
        let f = f.clone();
        Box::new(move |b: B| f(a.clone(), b))
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let add = |a, b| a + b;
</span><span class="boring">    let curried_add = curry(add);
</span><span class="boring">    let add_5 = curried_add(5);
</span><span class="boring">    assert_eq!(add_5(3), 8);
</span><span class="boring">}</span></code></pre></pre>
<p><em>Note: This strictly follows the type signature but requires allocation (<code>Box</code>) and cloning to satisfy the borrow checker for arbitrary <code>A</code>, <code>B</code>. In idiomatic Rust, we rarely "curry" manually, but the concept stands.</em></p>
<h3 id="exercise-24-uncurry"><a class="header" href="#exercise-24-uncurry">Exercise 2.4 (Uncurry)</a></h3>
<pre><pre class="playground"><code class="language-rust">pub fn uncurry&lt;A, B, C, F&gt;(f: F) -&gt; impl Fn(A, B) -&gt; C
where
    F: Fn(A) -&gt; Box&lt;dyn Fn(B) -&gt; C&gt; + 'static,
{
    move |a: A, b: B| {
        let g = f(a);
        g(b)
    }
}
<span class="boring">fn main() {} // Usage requires curry to be useful test</span></code></pre></pre>
<h3 id="exercise-25-compose"><a class="header" href="#exercise-25-compose">Exercise 2.5 (Compose)</a></h3>
<p>Implement the higher-order function that composes two functions (e.g., compose <code>extract_json</code> and <code>execute_tool</code>).</p>
<pre><pre class="playground"><code class="language-rust">pub fn compose&lt;A, B, C, F, G&gt;(f: F, g: G) -&gt; impl Fn(A) -&gt; C
where
    F: Fn(B) -&gt; C + 'static,
    G: Fn(A) -&gt; B + 'static,
    A: 'static,
{
    move |a: A| f(g(a))
}
<span class="boring">fn main() {
</span><span class="boring">   let f = |x| x + 1;
</span><span class="boring">   let g = |x| x * 2;
</span><span class="boring">   let h = compose(f, g);
</span><span class="boring">   assert_eq!(h(5), 11);
</span><span class="boring">}</span></code></pre></pre>
<h2 id="26-summary"><a class="header" href="#26-summary">2.6 Summary</a></h2>
<p>We introduced Rust syntax, recursion, higher-order functions (Combined Tools), and polymorphism.</p>
<h2 id="27-references"><a class="header" href="#27-references">2.7 References</a></h2>
<ul>
<li><strong>Functions</strong>: <a href="https://doc.rust-lang.org/book/ch03-03-how-functions-work.html">The Rust Book Ch 3.3</a></li>
<li><strong>Generics (<code>&lt;T&gt;</code>)</strong>: <a href="https://doc.rust-lang.org/book/ch10-01-syntax.html">The Rust Book Ch 10.1</a></li>
<li><strong>Trait Bounds (<code>where F: Fn</code>)</strong>: <a href="https://doc.rust-lang.org/book/ch10-02-traits.html">The Rust Book Ch 10.2</a></li>
<li><strong>Closures &amp; Iterators</strong>: <a href="https://doc.rust-lang.org/book/ch13-00-functional-features.html">The Rust Book Ch 13</a></li>
<li><strong>Rust By Example (Functions)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/fn.html">Functions</a></li>
<li><strong>Rust By Example (Closures)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/fn/closures.html">Closures</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-3-context-windows-functional-data-structures"><a class="header" href="#chapter-3-context-windows-functional-data-structures">Chapter 3: Context Windows (Functional Data Structures)</a></h1>
<p>In this chapter, we’ll learn the concept of functional data structures and how to work with them. In the world of Large Language Models (LLMs), managing the <strong>Context Window</strong> is critical. We often need efficient ways to manage conversation history, truncate old messages, or summarize dialogue without copying massive amounts of text.</p>
<p>We’ll use this as an opportunity to introduce how data types are defined in functional programming, learn about the related technique of pattern matching, and get practice writing and generalizing pure functions.</p>
<h2 id="31-defining-functional-data-structures"><a class="header" href="#31-defining-functional-data-structures">3.1 Defining functional data structures</a></h2>
<p>A functional data structure is operated on using only pure functions. Functional data structures are by definition immutable. This is perfect for maintaining a <strong>Message History</strong> where we might want to fork a conversation (branching paths) without copying the entire shared history.</p>
<p>In Rust, the most ubiquitous functional data structure, the singly linked list, can be defined using an <code>enum</code>. To enable <strong>data sharing</strong> (persistence) as described in functional literature, we use <code>Rc</code> (Reference Counting) instead of <code>Box</code> (unique ownership). This allows multiple conversation branches to share the same tail segments.</p>
<pre><pre class="playground"><code class="language-rust">use std::rc::Rc;

#[derive(Clone, Debug)]
pub enum List&lt;A&gt; {
    Nil,
    Cons(A, Rc&lt;List&lt;A&gt;&gt;),
}

use self::List::*;

impl&lt;A&gt; Default for List&lt;A&gt; {
    fn default() -&gt; Self {
        Nil
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let history: List&lt;&amp;str&gt; = List::Cons("User: Hello", Rc::new(List::Nil));
</span><span class="boring">    println!("{:?}", history);
</span><span class="boring">}</span></code></pre></pre>
<p>Let’s look at the definition. <code>enum List</code> has two variants: <code>Nil</code> (empty) and <code>Cons</code> (non-empty). <code>Cons</code> holds a value of type <code>A</code> (a Message) and a reference-counted pointer <code>Rc</code> to the rest of the list (Previous history).</p>
<h3 id="data-sharing"><a class="header" href="#data-sharing">Data Sharing</a></h3>
<p>When we add a new message to the history, we return a new list <code>Cons(msg, Rc::new(history))</code>. We don't copy the old history; we just reuse it. This is called data sharing. Functional data structures are <strong>persistent</strong>, meaning existing references (older snapshots of the context) are never changed by operations.</p>
<h2 id="32-pattern-matching"><a class="header" href="#32-pattern-matching">3.2 Pattern matching</a></h2>
<p>Rust supports pattern matching via <code>match</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn total_tokens(messages: &amp;List&lt;i32&gt;) -&gt; i32 {
    match messages {
        Nil =&gt; 0,
        Cons(tokens, rest) =&gt; tokens + total_tokens(rest),
    }
}

pub fn product_probabilities(probs: &amp;List&lt;f64&gt;) -&gt; f64 {
    match probs {
        Nil =&gt; 1.0,
        Cons(0.0, _) =&gt; 0.0, // Short-circuit if probability is 0
        Cons(p, rest) =&gt; p * product_probabilities(rest),
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let history = Cons(100, Rc::new(Cons(200, Rc::new(Nil))));
</span><span class="boring">    assert_eq!(total_tokens(&amp;history), 300);
</span><span class="boring">}</span></code></pre></pre>
<h3 id="exercise-31"><a class="header" href="#exercise-31">Exercise 3.1</a></h3>
<p>What will be the result of the match expression?
<em>Answer: The match expression in the book (translated to Rust syntax) would match the third case <code>x + y</code>, resulting in 3.</em></p>
<h2 id="33-data-sharing-in-functional-data-structures"><a class="header" href="#33-data-sharing-in-functional-data-structures">3.3 Data sharing in functional data structures</a></h2>
<h3 id="exercise-32-tail-trim-oldest"><a class="header" href="#exercise-32-tail-trim-oldest">Exercise 3.2: Tail (Trim Oldest)</a></h3>
<p>Implement the function <code>tail</code> for removing the first element ("trimming the most recent message" if defined as cons-stack, or "oldest" if defined as queue). In a List, <code>Cons</code> adds to the front. So <code>tail</code> removes the most recent addition.
<em>Note: In an immutable list, accessing the "rest" is O(1).</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn tail&lt;A&gt;(l: &amp;List&lt;A&gt;) -&gt; Option&lt;&amp;Rc&lt;List&lt;A&gt;&gt;&gt; {
    match l {
        Nil =&gt; None,
        Cons(_, xs) =&gt; Some(xs),
    }
}
<span class="boring">fn main() {
</span><span class="boring">   let list = Cons(1, Rc::new(Nil));
</span><span class="boring">   assert!(tail(&amp;list).is_some());
</span><span class="boring">}</span></code></pre></pre>
<p><em>Note: In Rust, returning a reference to the tail <code>&amp;Rc</code> works if we borrow the input. To return an owned persistent list, we would return <code>Rc&lt;List&lt;A&gt;&gt;</code> by cloning the pointer (cheap).</em></p>
<h3 id="exercise-33-set-head-replace-most-recent-message"><a class="header" href="#exercise-33-set-head-replace-most-recent-message">Exercise 3.3: Set Head (Replace Most Recent Message)</a></h3>
<p>Implement <code>set_head</code>. Useful for "Regenerating" the last response.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Debug)] enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn set_head&lt;A&gt;(l: &amp;List&lt;A&gt;, h: A) -&gt; List&lt;A&gt; 
where A: Clone {
    match l {
        Nil =&gt; panic!("set_head on empty history"), // Or return Result
        Cons(_, xs) =&gt; Cons(h, xs.clone()),
    }
}
<span class="boring">fn main() {
</span><span class="boring">   let list = Cons(1, Rc::new(Nil));
</span><span class="boring">   let new_list = set_head(&amp;list, 2);
</span><span class="boring">}</span></code></pre></pre>
<h3 id="exercise-34-drop-truncate-n-messages"><a class="header" href="#exercise-34-drop-truncate-n-messages">Exercise 3.4: Drop (Truncate N messages)</a></h3>
<p>Generalize <code>tail</code> to <code>drop</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn drop&lt;A&gt;(l: &amp;List&lt;A&gt;, n: usize) -&gt; &amp;List&lt;A&gt; {
    if n == 0 {
        return l;
    }
    match l {
        Nil =&gt; &amp;Nil,
        Cons(_, xs) =&gt; drop(xs, n - 1),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-35-dropwhile-truncate-until-condition"><a class="header" href="#exercise-35-dropwhile-truncate-until-condition">Exercise 3.5: DropWhile (Truncate until condition)</a></h3>
<p>Useful for "Remove messages until System Prompt".</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn drop_while&lt;A, F&gt;(l: &amp;List&lt;A&gt;, f: F) -&gt; &amp;List&lt;A&gt; 
where F: Fn(&amp;A) -&gt; bool {
    match l {
        Cons(h, t) if f(h) =&gt; drop_while(t, f),
        _ =&gt; l,
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-36-init-remove-oldest-message"><a class="header" href="#exercise-36-init-remove-oldest-message">Exercise 3.6: Init (Remove oldest message)</a></h3>
<p>Implement a function <code>init</code> that returns a List consisting of all but the last element (the oldest message).
<em>Why can't this be constant time? Because in a singly linked list <code>Cons(A, Rest)</code>, the end is far away. We must rebuild the path.</em></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn init&lt;A: Clone&gt;(l: &amp;List&lt;A&gt;) -&gt; List&lt;A&gt; {
    match l {
        Nil =&gt; panic!("init of empty list"),
        Cons(_, xs) if matches!(**xs, Nil) =&gt; Nil,
        Cons(h, xs) =&gt; Cons(h.clone(), Rc::new(init(xs))),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="34-recursion-over-lists-and-generalizing-to-higher-order-functions"><a class="header" href="#34-recursion-over-lists-and-generalizing-to-higher-order-functions">3.4 Recursion over lists and generalizing to higher-order functions</a></h2>
<h3 id="exercise-37---315-folds-context-summarization"><a class="header" href="#exercise-37---315-folds-context-summarization">Exercise 3.7 - 3.15: Folds (Context Summarization)</a></h3>
<p>Folding is the essence of <strong>Summarization</strong>. You take a list of messages and reduce them to a single value (a Summary).</p>
<p><strong>Exercise 3.9: Length (Message Count)</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span><span class="boring">fn fold_right&lt;A, B, F&gt;(l: &amp;List&lt;A&gt;, z: B, f: F) -&gt; B where F: Fn(&amp;A, B) -&gt; B + Clone { match l { Nil =&gt; z, Cons(h, t) =&gt; f(h, fold_right(t, z, f.clone())) } } 
</span>pub fn count_messages&lt;A&gt;(l: &amp;List&lt;A&gt;) -&gt; usize {
    fold_right(l, 0, |_, acc| acc + 1)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p><strong>Exercise 3.10: Fold Left (Iterative Summarization)</strong>
Ideal for large context windows to avoid stack overflow.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span>pub fn fold_left&lt;A, B, F&gt;(l: &amp;List&lt;A&gt;, z: B, f: F) -&gt; B 
where F: Fn(B, &amp;A) -&gt; B {
    match l {
        Nil =&gt; z,
        Cons(h, t) =&gt; fold_left(t, f(z, h), f),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p><strong>Exercise 3.12: Reverse (Chronological Sorting)</strong>
Linked Lists are usually built in reverse order (stack). To get chronological order for the LLM, we reverse.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] enum List&lt;A&gt; { Nil, Cons(A, Rc&lt;List&lt;A&gt;&gt;) }
</span><span class="boring">use self::List::*;
</span><span class="boring">pub fn fold_left&lt;A, B, F&gt;(l: &amp;List&lt;A&gt;, z: B, f: F) -&gt; B where F: Fn(B, &amp;A) -&gt; B { match l { Nil =&gt; z, Cons(h, t) =&gt; fold_left(t, f(z, h), f), } }
</span>pub fn reverse&lt;A: Clone&gt;(l: &amp;List&lt;A&gt;) -&gt; List&lt;A&gt; {
    fold_left(l, Nil, |acc, h| Cons(h.clone(), Rc::new(acc)))
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="35-conversation-trees"><a class="header" href="#35-conversation-trees">3.5 Conversation Trees</a></h2>
<p>Algebraic data types can be used to define other data structures. A <strong>Conversation Tree</strong> represents branching dialogue paths.</p>
<pre><pre class="playground"><code class="language-rust">pub enum Tree&lt;A&gt; {
    Leaf(A),
    Branch(Box&lt;Tree&lt;A&gt;&gt;, Box&lt;Tree&lt;A&gt;&gt;),
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p><em>Note: For Trees, <code>Box</code> (unique ownership) is often sufficient unless we need DAGs or explicit sharing.</em></p>
<h3 id="exercise-325-size-total-turns"><a class="header" href="#exercise-325-size-total-turns">Exercise 3.25: Size (Total Turns)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">enum Tree&lt;A&gt; { Leaf(A), Branch(Box&lt;Tree&lt;A&gt;&gt;, Box&lt;Tree&lt;A&gt;&gt;) }
</span>pub fn count_turns&lt;A&gt;(t: &amp;Tree&lt;A&gt;) -&gt; usize {
    match t {
        Tree::Leaf(_) =&gt; 1,
        Tree::Branch(l, r) =&gt; 1 + count_turns(l) + count_turns(r),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-326-maximum-max-token-count"><a class="header" href="#exercise-326-maximum-max-token-count">Exercise 3.26: Maximum (Max Token Count)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">enum Tree&lt;A&gt; { Leaf(A), Branch(Box&lt;Tree&lt;A&gt;&gt;, Box&lt;Tree&lt;A&gt;&gt;) }
</span>pub fn max_token_usage(t: &amp;Tree&lt;i32&gt;) -&gt; i32 {
    match t {
        Tree::Leaf(v) =&gt; *v,
        Tree::Branch(l, r) =&gt; max_token_usage(l).max(max_token_usage(r)),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-328-map-sanitize-messages"><a class="header" href="#exercise-328-map-sanitize-messages">Exercise 3.28: Map (Sanitize Messages)</a></h3>
<p>Apply a function (e.g., PII Redaction) to every node.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">enum Tree&lt;A&gt; { Leaf(A), Branch(Box&lt;Tree&lt;A&gt;&gt;, Box&lt;Tree&lt;A&gt;&gt;) }
</span>pub fn map_conversation&lt;A, B, F&gt;(t: &amp;Tree&lt;A&gt;, f: &amp;F) -&gt; Tree&lt;B&gt;
where F: Fn(&amp;A) -&gt; B {
    match t {
        Tree::Leaf(v) =&gt; Tree::Leaf(f(v)),
        Tree::Branch(l, r) =&gt; Tree::Branch(Box::new(map_conversation(l, f)), Box::new(map_conversation(r, f))),
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="36-summary"><a class="header" href="#36-summary">3.6 Summary</a></h2>
<p>We introduced algebraic data types (ADTs), <code>List</code> (Message History) and <code>Tree</code> (Conversation Branches), and higher-order functions like <code>map</code>, <code>fold</code> (Summarize), and <code>filter</code>.</p>
<h2 id="37-references"><a class="header" href="#37-references">3.7 References</a></h2>
<ul>
<li><strong>Rust Book Ch 6 (Enums)</strong>: <a href="https://doc.rust-lang.org/book/ch06-00-enums.html">The Rust Programming Language</a></li>
<li><strong>Rust Book Ch 15 (Smart Pointers/Box)</strong>: <a href="https://doc.rust-lang.org/book/ch15-00-smart-pointers.html">The Rust Programming Language</a></li>
<li><strong>Rust By Example (Enums)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/custom_types/enum.html">Custom Types</a></li>
<li><strong>Rust By Example (LinkedList)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/custom_types/enum/testcase_linked_list.html">Testcase: Linked List</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-4-handling-hallucinations-error-handling"><a class="header" href="#chapter-4-handling-hallucinations-error-handling">Chapter 4: Handling Hallucinations (Error Handling)</a></h1>
<p>Throwing exceptions is a side effect. In Agentic programming, we often deal with unreliable components: LLMs hallucinate, Tools fail, and APIs timeout. We prefer representing these failures as <strong>ordinary values</strong>. This preserves referential transparency and allows our Agents to reason about their own failures.</p>
<p>In this chapter, we re-create two standard library types: <code>Option</code> (Missing values) and <code>Either</code> (Failures with reasons).</p>
<h2 id="41-the-option-data-type"><a class="header" href="#41-the-option-data-type">4.1 The Option data type</a></h2>
<p>We represent the possibility of an undefined result (e.g., "Tool produced no output" or "Regex failed to capture") with <code>Option</code>.</p>
<pre><pre class="playground"><code class="language-rust">pub enum Option&lt;A&gt; {
    Some(A),
    None,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercises-41-basic-functions"><a class="header" href="#exercises-41-basic-functions">Exercises 4.1: Basic Functions</a></h3>
<p>Implement <code>map</code>, <code>flat_map</code>, <code>get_or_else</code>, <code>or_else</code>, and <code>filter</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone, Copy)] pub enum Option&lt;A&gt; { Some(A), None }
</span>impl&lt;A&gt; Option&lt;A&gt; {
    pub fn map&lt;B, F&gt;(self, f: F) -&gt; Option&lt;B&gt; 
    where F: FnOnce(A) -&gt; B {
        match self {
            Option::Some(a) =&gt; Option::Some(f(a)),
            Option::None =&gt; Option::None,
        }
    }

    pub fn flat_map&lt;B, F&gt;(self, f: F) -&gt; Option&lt;B&gt;
    where F: FnOnce(A) -&gt; Option&lt;B&gt; {
        match self {
            Option::Some(a) =&gt; f(a),
            Option::None =&gt; Option::None, // Failure propagates
        }
    }

    pub fn get_or_else(self, default: A) -&gt; A {
        match self {
            Option::Some(a) =&gt; a,
            Option::None =&gt; default, // Fallback value
        }
    }

    pub fn or_else&lt;F&gt;(self, ob: F) -&gt; Option&lt;A&gt;
    where F: FnOnce() -&gt; Option&lt;A&gt; {
        match self {
            Option::Some(_) =&gt; self,
            Option::None =&gt; ob(), // Try another strategy (Fallback Agent)
        }
    }

    pub fn filter&lt;F&gt;(self, f: F) -&gt; Option&lt;A&gt;
    where F: FnOnce(&amp;A) -&gt; bool {
        match self {
            Option::Some(a) if f(&amp;a) =&gt; Option::Some(a),
            _ =&gt; Option::None,
        }
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-42-variance-latency-analysis"><a class="header" href="#exercise-42-variance-latency-analysis">Exercise 4.2: Variance (Latency Analysis)</a></h3>
<p>Implement <code>variance</code> for analyzing API latency stability.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone, Copy)] pub enum Option&lt;A&gt; { Some(A), None }
</span><span class="boring">impl&lt;A&gt; Option&lt;A&gt; { 
</span><span class="boring">   pub fn flat_map&lt;B, F&gt;(self, f: F) -&gt; Option&lt;B&gt; where F: FnOnce(A) -&gt; Option&lt;B&gt; { match self { Option::Some(a) =&gt; f(a), Option::None =&gt; Option::None } } 
</span><span class="boring">}
</span>fn average_latency(latencies: &amp;[f64]) -&gt; Option&lt;f64&gt; {
    if latencies.is_empty() {
        Option::None
    } else {
        Option::Some(latencies.iter().sum::&lt;f64&gt;() / latencies.len() as f64)
    }
}

pub fn latency_variance(latencies: &amp;[f64]) -&gt; Option&lt;f64&gt; {
    average_latency(latencies).flat_map(|m| average_latency(&amp;latencies.iter().map(|x| (x - m).powi(2)).collect::&lt;Vec&lt;_&gt;&gt;()))
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-43-map2-combine-tool-outputs"><a class="header" href="#exercise-43-map2-combine-tool-outputs">Exercise 4.3: Map2 (Combine Tool Outputs)</a></h3>
<p>Combine two Option values (e.g. <code>search_result</code> and <code>weather_data</code>). If either failed, the combination fails.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#[derive(Clone, Copy)] pub enum Option&lt;A&gt; { Some(A), None }
</span><span class="boring">impl&lt;A&gt; Option&lt;A&gt; { 
</span><span class="boring">   pub fn flat_map&lt;B, F&gt;(self, f: F) -&gt; Option&lt;B&gt; where F: FnOnce(A) -&gt; Option&lt;B&gt; { match self { Option::Some(a) =&gt; f(a), Option::None =&gt; Option::None } } 
</span><span class="boring">   pub fn map&lt;B, F&gt;(self, f: F) -&gt; Option&lt;B&gt; where F: FnOnce(A) -&gt; B { match self { Option::Some(a) =&gt; Option::Some(f(a)), Option::None =&gt; Option::None } }
</span><span class="boring">}
</span>pub fn combine_tool_outputs&lt;A, B, C, F&gt;(a: Option&lt;A&gt;, b: Option&lt;B&gt;, f: F) -&gt; Option&lt;C&gt;
where F: FnOnce(A, B) -&gt; C {
    a.flat_map(|aa| b.map(|bb| f(aa, bb)))
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-44-sequence-batch-execution"><a class="header" href="#exercise-44-sequence-batch-execution">Exercise 4.4: Sequence (Batch Execution)</a></h3>
<p>Combine a list of optional results into one Option containing a list. If <em>any</em> tool failed, the whole batch fails.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub enum Option&lt;A&gt; { Some(A), None }
</span>pub fn sequence_results&lt;A&gt;(a: Vec&lt;Option&lt;A&gt;&gt;) -&gt; Option&lt;Vec&lt;A&gt;&gt; {
    let mut res = Vec::new();
    for opt in a {
        match opt {
            Option::Some(val) =&gt; res.push(val),
            Option::None =&gt; return Option::None,
        }
    }
    Option::Some(res)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-45-traverse-parallel-execution"><a class="header" href="#exercise-45-traverse-parallel-execution">Exercise 4.5: Traverse (Parallel Execution)</a></h3>
<p>Map a function (e.g., <code>execute_tool</code>) over a list of inputs.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub enum Option&lt;A&gt; { Some(A), None }
</span>pub fn traverse_executions&lt;A, B, F&gt;(inputs: Vec&lt;A&gt;, f: F) -&gt; Option&lt;Vec&lt;B&gt;&gt;
where F: Fn(A) -&gt; Option&lt;B&gt; {
    let mut res = Vec::new();
    for x in inputs {
        match f(x) {
            Option::Some(y) =&gt; res.push(y),
            Option::None =&gt; return Option::None,
        }
    }
    Option::Some(res)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="44-the-either-data-type"><a class="header" href="#44-the-either-data-type">4.4 The Either data type</a></h2>
<p><code>Option</code> doesn't tell us <em>why</em> something failed (e.g., "Rate Limit Exceeded" vs "Invalid JSON"). <code>Either</code> lets us track a failure reason.</p>
<pre><pre class="playground"><code class="language-rust">pub enum Either&lt;E, A&gt; {
    Left(E), // The "Error" or "Refusal"
    Right(A), // The "Success" or "Tool Output"
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-46-basic-functions-on-either"><a class="header" href="#exercise-46-basic-functions-on-either">Exercise 4.6: Basic Functions on Either</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub enum Either&lt;E, A&gt; { Left(E), Right(A) }
</span>impl&lt;E, A&gt; Either&lt;E, A&gt; {
    pub fn map&lt;B, F&gt;(self, f: F) -&gt; Either&lt;E, B&gt;
    where F: FnOnce(A) -&gt; B {
        match self {
            Either::Right(a) =&gt; Either::Right(f(a)),
            Either::Left(e) =&gt; Either::Left(e),
        }
    }
    
    pub fn flat_map&lt;EE, B, F&gt;(self, f: F) -&gt; Either&lt;EE, B&gt;
    where 
        F: FnOnce(A) -&gt; Either&lt;EE, B&gt;,
        EE: From&lt;E&gt; 
    {
        match self {
            Either::Right(a) =&gt; f(a),
            Either::Left(e) =&gt; Either::Left(EE::from(e)),
        }
    }
    
    pub fn or_else&lt;EE, F&gt;(self, b: F) -&gt; Either&lt;EE, A&gt;
    where 
        F: FnOnce() -&gt; Either&lt;EE, A&gt;,
        EE: From&lt;E&gt;
    {
        match self {
            Either::Right(a) =&gt; Either::Right(a),
            Either::Left(_) =&gt; b(), // Retry!
        }
    }
    
    pub fn map2&lt;EE, B, C, F&gt;(self, b: Either&lt;EE, B&gt;, f: F) -&gt; Either&lt;EE, C&gt;
    where 
        F: FnOnce(A, B) -&gt; C,
        EE: From&lt;E&gt; 
    {
        self.flat_map(|aa| b.map(|bb| f(aa, bb)))
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p><em>Note: In Rust, handling different error types <code>E</code> and <code>EE</code> usually requires <code>From</code> or a common Error trait.</em></p>
<h3 id="exercise-47-sequence-and-traverse-for-either"><a class="header" href="#exercise-47-sequence-and-traverse-for-either">Exercise 4.7: Sequence and Traverse for Either</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub enum Either&lt;E, A&gt; { Left(E), Right(A) }
</span>pub fn sequence_execution&lt;E, A&gt;(es: Vec&lt;Either&lt;E, A&gt;&gt;) -&gt; Either&lt;E, Vec&lt;A&gt;&gt; {
    traverse_execution(es, |x| x)
}

pub fn traverse_execution&lt;E, A, B, F&gt;(as_vec: Vec&lt;A&gt;, f: F) -&gt; Either&lt;E, Vec&lt;B&gt;&gt;
where F: Fn(A) -&gt; Either&lt;E, B&gt; {
    let mut res = Vec::new();
    for a in as_vec {
        match f(a) {
            Either::Right(b) =&gt; res.push(b),
            Either::Left(e) =&gt; return Either::Left(e),
        }
    }
    Either::Right(res)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-48-accumulating-errors-validation"><a class="header" href="#exercise-48-accumulating-errors-validation">Exercise 4.8: Accumulating Errors (Validation)</a></h3>
<p>To report <em>both</em> "Model Refusal" AND "Context Limit Exceeded", we would need a data structure that can hold multiple errors, like <code>Validation&lt;Vec&lt;E&gt;, A&gt;</code>. <code>Either</code> stops at the first error (fail-fast).</p>
<h2 id="45-summary"><a class="header" href="#45-summary">4.5 Summary</a></h2>
<p>We learned to handle Agent failures and hallucinations as values using <code>Option</code> and <code>Either</code>.</p>
<h2 id="46-references"><a class="header" href="#46-references">4.6 References</a></h2>
<ul>
<li><strong>Error Handling</strong>: <a href="https://doc.rust-lang.org/book/ch09-00-error-handling.html">The Rust Book Ch 9</a></li>
<li><strong>Recoverable Errors (Result)</strong>: <a href="https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html">The Rust Book Ch 9.2</a></li>
<li><strong>The Option Enum</strong>: <a href="https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html?highlight=Option#the-option-enum-and-its-advantages-over-null-values">The Rust Book Ch 6.1</a></li>
<li><strong>Rust By Example (Error Handling)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/error.html">Error Handling</a></li>
<li><strong>Rust Pattern (Result/Option)</strong>: <a href="https://rust-unofficial.github.io/patterns/idioms/error-handling.html">Idioms</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-5-token-streaming-strictness-and-laziness"><a class="header" href="#chapter-5-token-streaming-strictness-and-laziness">Chapter 5: Token Streaming (Strictness and Laziness)</a></h1>
<p>In this chapter, we explore <strong>non-strictness</strong> (laziness) to improve efficiency and modularity. In the context of LLMs, this is crucial for <strong>Token Streaming</strong>. We don't want to wait for the entire 4,000-token response to be generated before showing the first word. We need a <code>TokenStream</code> that fuses sequences of transformations (like filtering or stopping criteria) without realizing the full buffer.</p>
<h2 id="51-strict-and-non-strict-functions"><a class="header" href="#51-strict-and-non-strict-functions">5.1 Strict and non-strict functions</a></h2>
<p>Strict functions evaluate their arguments <em>before</em> the function body is executed. Non-strict functions may choose not to evaluate arguments.</p>
<p>In Rust, arguments are strictly evaluated by default. To simulate non-strictness (lazy loading), we can pass a closure (thunk) <code>Fn() -&gt; A</code> instead of a value <code>A</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// logical AND is non-strict in the second argument
// stop_sequence_met &amp;&amp; { println!("Generation stopped!"); true } 
<span class="boring">}</span></code></pre></pre>
<h2 id="52-an-extended-example-token-streams"><a class="header" href="#52-an-extended-example-token-streams">5.2 An extended example: Token Streams</a></h2>
<p>We define a <code>TokenStream</code> (lazy list). In Rust, we use closures wrapped in <code>Rc</code> (for sharing) to represent these thunks (un-generated tokens).</p>
<pre><pre class="playground"><code class="language-rust">use std::rc::Rc;

#[derive(Clone)]
pub enum TokenStream&lt;A&gt; {
    Empty,
    Cons(Rc&lt;dyn Fn() -&gt; A&gt;, Rc&lt;dyn Fn() -&gt; TokenStream&lt;A&gt;&gt;),
}
// Note: We avoid memoization complexity for this basic translation. 
// In a production specific persistent stream, one might use `lazy_static` or `OnceCell`.
<span class="boring">fn main() {
</span><span class="boring">   // verify basic construction
</span><span class="boring">   let _ = TokenStream::Cons(Rc::new(|| "Hello"), Rc::new(|| TokenStream::Empty));
</span><span class="boring">}</span></code></pre></pre>
<h3 id="exercise-51-collect_text-to_vec"><a class="header" href="#exercise-51-collect_text-to_vec">Exercise 5.1: collect_text (to_vec)</a></h3>
<p>Force the stream into a strict <code>Vec</code> (Full Response).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] pub enum TokenStream&lt;A&gt; { Empty, Cons(Rc&lt;dyn Fn() -&gt; A&gt;, Rc&lt;dyn Fn() -&gt; TokenStream&lt;A&gt;&gt;) }
</span>// impl TokenStream&lt;A&gt;
pub fn collect_text&lt;A&gt;(s: &amp;TokenStream&lt;A&gt;) -&gt; Vec&lt;A&gt; { 
    match s {
        TokenStream::Empty =&gt; Vec::new(),
        TokenStream::Cons(h, t) =&gt; {
            let mut v = vec![h()];
            v.extend(collect_text(&amp;t()));
            v
        }
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-52-limit_tokens-take-and-skip_preamble-drop"><a class="header" href="#exercise-52-limit_tokens-take-and-skip_preamble-drop">Exercise 5.2: limit_tokens (take) and skip_preamble (drop)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] pub enum TokenStream&lt;A&gt; { Empty, Cons(Rc&lt;dyn Fn() -&gt; A&gt;, Rc&lt;dyn Fn() -&gt; TokenStream&lt;A&gt;&gt;) }
</span><span class="boring">impl&lt;A&gt; TokenStream&lt;A&gt; { fn cons&lt;F, S&gt;(h: F, t: S) -&gt; Self where F: Fn() -&gt; A + 'static, S: Fn() -&gt; TokenStream&lt;A&gt; + 'static { TokenStream::Cons(Rc::new(h), Rc::new(t)) } }
</span>pub fn limit_tokens&lt;A: 'static&gt;(s: &amp;TokenStream&lt;A&gt;, n: usize) -&gt; TokenStream&lt;A&gt; {
    if n == 0 {
        TokenStream::Empty
    } else {
        match s {
            TokenStream::Empty =&gt; TokenStream::Empty,
            TokenStream::Cons(h, t) =&gt; {
                let h = h.clone();
                let t = t.clone();
                TokenStream::cons(move || h(), move || limit_tokens(&amp;t(), n - 1))
            }
        }
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-53-take_while"><a class="header" href="#exercise-53-take_while">Exercise 5.3: take_while</a></h3>
<p>Return all tokens until a Stop Sequence is met.</p>
<h2 id="53-separating-program-description-from-evaluation"><a class="header" href="#53-separating-program-description-from-evaluation">5.3 Separating program description from evaluation</a></h2>
<p>Laziness lets us separate the description of an expression (the pipeline) from its evaluation (the generation).</p>
<h3 id="exercise-54-validate_stream-for_all"><a class="header" href="#exercise-54-validate_stream-for_all">Exercise 5.4: validate_stream (for_all)</a></h3>
<p>Check that all tokens in the Stream match a given predicate (e.g. "Is Safe"), terminating early if a violation occurs.</p>
<h3 id="exercise-55-take_while-using-fold_right"><a class="header" href="#exercise-55-take_while-using-fold_right">Exercise 5.5: take_while using fold_right</a></h3>
<h3 id="exercise-56-head_option-peek_first_token"><a class="header" href="#exercise-56-head_option-peek_first_token">Exercise 5.6: head_option (peek_first_token)</a></h3>
<h3 id="exercise-57-map-filter-append-flat_map-using-fold_right"><a class="header" href="#exercise-57-map-filter-append-flat_map-using-fold_right">Exercise 5.7: map, filter, append, flat_map using fold_right</a></h3>
<h2 id="54-infinite-streams-heartbeats"><a class="header" href="#54-infinite-streams-heartbeats">5.4 Infinite streams (Heartbeats)</a></h2>
<p>Because functions are incremental, they work for infinite streams (e.g., a "Waiting" animation or Heartbeat signal).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] pub enum TokenStream&lt;A&gt; { Empty, Cons(Rc&lt;dyn Fn() -&gt; A&gt;, Rc&lt;dyn Fn() -&gt; TokenStream&lt;A&gt;&gt;) }
</span><span class="boring">impl&lt;A&gt; TokenStream&lt;A&gt; { fn cons&lt;F, S&gt;(h: F, t: S) -&gt; Self where F: Fn() -&gt; A + 'static, S: Fn() -&gt; TokenStream&lt;A&gt; + 'static { TokenStream::Cons(Rc::new(h), Rc::new(t)) } }
</span>pub fn heartbeats() -&gt; TokenStream&lt;&amp;'static str&gt; {
    TokenStream::cons(|| ".", heartbeats)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-58-constant"><a class="header" href="#exercise-58-constant">Exercise 5.8: constant</a></h3>
<h3 id="exercise-59-from"><a class="header" href="#exercise-59-from">Exercise 5.9: from</a></h3>
<h3 id="exercise-510-fibs-loading_simulation"><a class="header" href="#exercise-510-fibs-loading_simulation">Exercise 5.10: fibs (loading_simulation)</a></h3>
<h3 id="exercise-511-unfold-generate_tokens"><a class="header" href="#exercise-511-unfold-generate_tokens">Exercise 5.11: unfold (generate_tokens)</a></h3>
<p>A general stream-building function (corecursion). Ideal for wrapping an LLM API that returns chunks.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Clone)] pub enum TokenStream&lt;A&gt; { Empty, Cons(Rc&lt;dyn Fn() -&gt; A&gt;, Rc&lt;dyn Fn() -&gt; TokenStream&lt;A&gt;&gt;) }
</span><span class="boring">impl&lt;A&gt; TokenStream&lt;A&gt; { fn cons&lt;F, S&gt;(h: F, t: S) -&gt; Self where F: Fn() -&gt; A + 'static, S: Fn() -&gt; TokenStream&lt;A&gt; + 'static { TokenStream::Cons(Rc::new(h), Rc::new(t)) } }
</span>pub fn generate_tokens&lt;A, S, F&gt;(initial_state: S, generator: F) -&gt; TokenStream&lt;A&gt;
where A: Clone + 'static, S: Clone + 'static, F: Fn(S) -&gt; Option&lt;(A, S)&gt; + 'static + Clone {
    match generator(initial_state) {
        Some((token, next_state)) =&gt; {
            let gen = generator.clone();
            TokenStream::cons(move || token.clone(), move || generate_tokens(next_state.clone(), gen.clone()))
        },
        None =&gt; TokenStream::Empty,
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-512-fibs-from-constant-via-unfold"><a class="header" href="#exercise-512-fibs-from-constant-via-unfold">Exercise 5.12: fibs, from, constant, via unfold</a></h3>
<h3 id="exercise-513-map-take-take_while-zip_with-zip_all-via-unfold"><a class="header" href="#exercise-513-map-take-take_while-zip_with-zip_all-via-unfold">Exercise 5.13: map, take, take_while, zip_with, zip_all via unfold</a></h3>
<h3 id="exercise-514-starts_with"><a class="header" href="#exercise-514-starts_with">Exercise 5.14: starts_with</a></h3>
<h3 id="exercise-515-tails"><a class="header" href="#exercise-515-tails">Exercise 5.15: tails</a></h3>
<h3 id="exercise-516-scan_right"><a class="header" href="#exercise-516-scan_right">Exercise 5.16: scan_right</a></h3>
<h2 id="55-summary"><a class="header" href="#55-summary">5.5 Summary</a></h2>
<p>Laziness improves modularity by decoupling the description of a token pipeline from its execution.</p>
<h2 id="56-references"><a class="header" href="#56-references">5.6 References</a></h2>
<ul>
<li><strong>Rust Book Ch 13 (Iterators)</strong>: <a href="https://doc.rust-lang.org/book/ch13-02-iterators.html">The Rust Programming Language</a></li>
<li><strong>Rust By Example (Iterators)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/trait/iter.html">Iterators</a></li>
<li><strong>Rust Patterns (Lazy Evaluation)</strong>: <a href="https://rust-unofficial.github.io/patterns/idioms/lazy-evaluation.html">Idioms</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-6-agent-memory-purely-functional-state"><a class="header" href="#chapter-6-agent-memory-purely-functional-state">Chapter 6: Agent Memory (Purely Functional State)</a></h1>
<p>Handling state without side effects is a core aspect of Agentic programming. Agents need to manage <strong>Memory</strong> (History, Context, Variables) as they execute steps. We use the <strong>State Monad</strong> pattern, where a state transition is a function <code>Memory -&gt; (Action, Memory)</code>.</p>
<h2 id="61-generating-random-tokens-mockllm"><a class="header" href="#61-generating-random-tokens-mockllm">6.1 Generating random tokens (MockLLM)</a></h2>
<p>To test our Agents deterministically, we need a Mock LLM that generates "Random" tokens but in a reproducible way.</p>
<pre><pre class="playground"><code class="language-rust">pub trait MockLLM {
    fn next_token(&amp;self) -&gt; (i32, Box&lt;dyn MockLLM&gt;);
}

#[derive(Clone)]
pub struct SimpleMockLLM {
    seed: i64,
}

impl SimpleMockLLM {
    pub fn new(seed: i64) -&gt; SimpleMockLLM {
        SimpleMockLLM { seed }
    }
}
<span class="boring">impl MockLLM for SimpleMockLLM {
</span><span class="boring">    fn next_token(&amp;self) -&gt; (i32, Box&lt;dyn MockLLM&gt;) {
</span><span class="boring">        let new_seed = (self.seed.wrapping_mul(0x5DEECE66D).wrapping_add(0xB)) &amp; 0xFFFFFFFFFFFF;
</span><span class="boring">        let next_rng = SimpleMockLLM { seed: new_seed };
</span><span class="boring">        let n = (new_seed &gt;&gt; 16) as i32;
</span><span class="boring">        (n, Box::new(next_rng))
</span><span class="boring">    }
</span><span class="boring">}
</span><span class="boring">fn main() {
</span><span class="boring">    let llm = SimpleMockLLM::new(42);
</span><span class="boring">    let (token1, _next_state) = llm.next_token();
</span><span class="boring">    println!("Generated token ID: {}", token1);
</span><span class="boring">}</span></code></pre></pre>
<h3 id="exercise-61-non_negative_token"><a class="header" href="#exercise-61-non_negative_token">Exercise 6.1: non_negative_token</a></h3>
<h3 id="exercise-62-double_precision_prob"><a class="header" href="#exercise-62-double_precision_prob">Exercise 6.2: double_precision_prob</a></h3>
<h3 id="exercise-63-int_double-double_int-double3"><a class="header" href="#exercise-63-int_double-double_int-double3">Exercise 6.3: int_double, double_int, double3</a></h3>
<h3 id="exercise-64-generate_token_list"><a class="header" href="#exercise-64-generate_token_list">Exercise 6.4: generate_token_list</a></h3>
<h2 id="64-a-better-api-for-state-actions"><a class="header" href="#64-a-better-api-for-state-actions">6.4 A better API for state actions</a></h2>
<p>We define <code>Sampler&lt;A&gt;</code> as a type alias for <code>Fn(MockLLM) -&gt; (A, MockLLM)</code>. This represents a probabilistic action.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait MockLLM {}
</span>type Sampler&lt;A&gt; = Box&lt;dyn Fn(Box&lt;dyn MockLLM&gt;) -&gt; (A, Box&lt;dyn MockLLM&gt;)&gt;;
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-65-double-via-map"><a class="header" href="#exercise-65-double-via-map">Exercise 6.5: double via map</a></h3>
<h3 id="exercise-66-map2"><a class="header" href="#exercise-66-map2">Exercise 6.6: map2</a></h3>
<h3 id="exercise-67-sequence"><a class="header" href="#exercise-67-sequence">Exercise 6.7: sequence</a></h3>
<h3 id="exercise-68-flat_map"><a class="header" href="#exercise-68-flat_map">Exercise 6.8: flat_map</a></h3>
<h3 id="exercise-69-map-and-map2-via-flat_map"><a class="header" href="#exercise-69-map-and-map2-via-flat_map">Exercise 6.9: map and map2 via flat_map</a></h3>
<h2 id="65-a-general-agent-state-generic"><a class="header" href="#65-a-general-agent-state-generic">6.5 A general Agent State generic</a></h2>
<p>We generalize <code>Sampler</code> to <code>Agent&lt;Memory, Action&gt;</code>. An Agent is simply a function that takes a memory state and returns an action (decision) plus the new memory state.</p>
<pre><pre class="playground"><code class="language-rust">// Agent&lt;Memory, Action&gt;
pub struct Agent&lt;S, A&gt;(pub Box&lt;dyn Fn(S) -&gt; (A, S)&gt;);
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-610-unit-map-map2-flat_map-sequence-for-agent"><a class="header" href="#exercise-610-unit-map-map2-flat_map-sequence-for-agent">Exercise 6.10: unit, map, map2, flat_map, sequence for Agent</a></h3>
<h2 id="66-purely-functional-imperative-programming"><a class="header" href="#66-purely-functional-imperative-programming">6.6 Purely functional imperative programming</a></h2>
<p>Using <code>Agent</code> (State Monad), we can write imperative-looking code using <code>flat_map</code> chains to represent an Agent's Thought Process.</p>
<h3 id="exercise-611-chatbot-state-machine"><a class="header" href="#exercise-611-chatbot-state-machine">Exercise 6.11: ChatBot State Machine</a></h3>
<p>Implement a finite state automaton for a simple ChatBot.</p>
<pre><pre class="playground"><code class="language-rust">pub enum Input {
    UserMessage,
    ModelCompletion,
}

pub struct ChatBot {
    pub awaiting_input: bool,
    pub context_tokens: i32,
    pub total_messages: i32,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>Rules:</p>
<ol>
<li><code>UserMessage</code> while <code>awaiting_input</code> -&gt; Transition to <code>!awaiting_input</code> (Generating).</li>
<li><code>ModelCompletion</code> while <code>!awaiting_input</code> -&gt; Transition to <code>awaiting_input</code> (Ready).</li>
<li><code>UserMessage</code> while Generating (busy) is ignored.</li>
<li><code>ModelCompletion</code> while Ready (idle) is ignored.</li>
</ol>
<h2 id="67-references"><a class="header" href="#67-references">6.7 References</a></h2>
<ul>
<li><strong>Rust Book Ch 17 (State Object Pattern)</strong>: <a href="https://doc.rust-lang.org/book/ch17-03-oo-design-patterns.html">The Rust Programming Language</a></li>
<li><strong>Rust By Example (Traits)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/trait.html">Traits</a></li>
<li><strong>Refactoring.Guru</strong>: <a href="https://refactoring.guru/design-patterns/state">State Pattern</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-7-parallel-agent-orchestration-purely-functional-parallelism"><a class="header" href="#chapter-7-parallel-agent-orchestration-purely-functional-parallelism">Chapter 7: Parallel Agent Orchestration (Purely Functional Parallelism)</a></h1>
<p>In this chapter, we will design a purely functional library for creating <strong>Parallel Agent Workflows</strong>. As we did in previous chapters, we won't jump straight to the implementation. Instead, we'll follow a process of <em>designing the API first</em>. We'll verify that our API is expressive enough to handle complex Agentic patterns like "Map-Reduce Research" or "Parallel Tool Execution".</p>
<p>This journey is particularly interesting in Rust. The compiler forces us to be rigorous about ownership and sharing across threads from day one. We will see how traits like <code>Send</code>, <code>Sync</code>, and types like <code>Arc</code> become fundamental building blocks of our Agent Orchestrator.</p>
<h2 id="71-designing-the-agent-orchestrator"><a class="header" href="#71-designing-the-agent-orchestrator">7.1 Designing the Agent Orchestrator</a></h2>
<p>Our goal is to create a library that can describe parallel agent tasks. Let's imagine we want to <strong>research a topic</strong> by searching multiple sources in parallel. We might use a divide-and-conquer approach:</p>
<pre><pre class="playground"><code class="language-rust">fn gather_research(sources: &amp;[String]) -&gt; String {
    if sources.len() &lt;= 1 {
        let source = sources.get(0).cloned().unwrap_or_default();
        search_source(&amp;source) // Assume this is slow!
    } else {
        let (l, r) = sources.split_at(sources.len() / 2);
        let left_result = gather_research(l);
        let right_result = gather_research(r);
        format!("{}\n{}", left_result, right_result)
    }
}
<span class="boring">fn search_source(s: &amp;str) -&gt; String { format!("Content from {}", s) }
</span><span class="boring">fn main() {
</span><span class="boring">    let sources = vec!["Wiki".to_string(), "News".to_string()];
</span><span class="boring">    let res = gather_research(&amp;sources);
</span><span class="boring">    assert!(res.contains("Wiki"));
</span><span class="boring">}</span></code></pre></pre>
<p>This implementation is sequential. To make it parallel, we need a way to say "search <code>l</code> and <code>r</code> in parallel". Let's invent a container type, let's call it <code>AgentTask&lt;A&gt;</code>, that represents a computation of type <code>A</code> that <em>might</em> be running in another thread (another Agent).</p>
<p>We need a way to take an evaluated result and wrap it (<code>completed_task</code>).
And we need a way to get the final result out (<code>await_result</code>).</p>
<pre><pre class="playground"><code class="language-rust">pub struct AgentTask&lt;A&gt;(std::marker::PhantomData&lt;A&gt;);

impl&lt;A&gt; AgentTask&lt;A&gt; {
    pub fn completed_task(a: A) -&gt; AgentTask&lt;A&gt; { AgentTask(std::marker::PhantomData) }
    pub fn await_result(self) -&gt; A { unimplemented!() }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>If we change <code>gather_research</code> to use <code>AgentTask</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span><span class="boring">impl&lt;A&gt; AgentTask&lt;A&gt; { fn completed_task(a: A) -&gt; AgentTask&lt;A&gt; { AgentTask(a) } fn await_result(self) -&gt; A { self.0 } }
</span><span class="boring">fn search_source(s: &amp;str) -&gt; String { format!("{}", s) }
</span>fn gather_research(sources: &amp;[String]) -&gt; String {
    if sources.len() &lt;= 1 {
        let source = sources.get(0).cloned().unwrap_or_default();
        search_source(&amp;source)
    } else {
        let (l, r) = sources.split_at(sources.len() / 2);
        // This is still sequential if evaluated immediately!
        let left_task: AgentTask&lt;String&gt; = AgentTask::completed_task(gather_research(l)); 
        let right_task: AgentTask&lt;String&gt; = AgentTask::completed_task(gather_research(r));
        
        format!("{}\n{}", left_task.await_result(), right_task.await_result())
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>We need a primitive that takes a <em>lazy</em> argument (a closure) to run it in the background. Let's call it <code>spawn_agent</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span>pub fn spawn_agent&lt;A, F&gt;(task: F) -&gt; AgentTask&lt;A&gt; 
where F: FnOnce() -&gt; AgentTask&lt;A&gt; + Send + 'static { task() }
<span class="boring">fn main() {}</span></code></pre></pre>
<p>In Rust, strict evaluation is the default. To prevent immediate execution, we pass a closure (a thunk). <code>spawn_agent</code> takes a thunk that returns an <code>AgentTask&lt;A&gt;</code>, and executes it on a worker thread.</p>
<p>However, we need to combine results. We need <code>join_results</code> (map2):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span>pub fn join_results&lt;A, B, C, F&gt;(task_a: AgentTask&lt;A&gt;, task_b: AgentTask&lt;B&gt;, merger: F) -&gt; AgentTask&lt;C&gt;
where F: Fn(A, B) -&gt; C { unimplemented!() }
<span class="boring">fn main() {}</span></code></pre></pre>
<p>With <code>completed_task</code>, <code>spawn_agent</code>, and <code>join_results</code>, our parallel researcher looks like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span><span class="boring">impl&lt;A&gt; AgentTask&lt;A&gt; { fn completed_task(a: A) -&gt; Self { AgentTask(a) } fn spawn_agent&lt;F&gt;(f: F) -&gt; Self where F: FnOnce() -&gt; Self { f() } fn join_results&lt;B, C, F&gt;(pa: AgentTask&lt;A&gt;, pb: AgentTask&lt;B&gt;, f: F) -&gt; AgentTask&lt;C&gt; where F: Fn(A, B) -&gt; C { AgentTask(f(pa.0, pb.0)) } }
</span><span class="boring">fn search_source(s: &amp;str) -&gt; String { format!("{}", s) }
</span>fn gather_research(sources: &amp;[String]) -&gt; AgentTask&lt;String&gt; {
    if sources.len() &lt;= 1 {
        let source = sources.get(0).cloned().unwrap_or_default();
        AgentTask::completed_task(search_source(&amp;source))
    } else {
        let (l, r) = sources.split_at(sources.len() / 2);
        AgentTask::join_results(
            AgentTask::spawn_agent(|| gather_research(l)),
            AgentTask::spawn_agent(|| gather_research(r)),
            |a, b| format!("{}\n{}", a, b)
        )
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>This looks purely functional! <code>gather_research</code> now returns a <em>description</em> of a workflow (<code>AgentTask&lt;String&gt;</code>), which we can execute later by calling <code>await_result</code>.</p>
<h2 id="72-a-function-representation-for-agenttask"><a class="header" href="#72-a-function-representation-for-agenttask">7.2 A Function Representation for <code>AgentTask</code></a></h2>
<p>What should <code>AgentTask&lt;A&gt;</code> actually <em>be</em>?
It is a function that takes an <code>Executor</code> (The Runtime) and returns a <code>Future[A]</code> (The Pending Result).</p>
<pre><pre class="playground"><code class="language-rust">use std::sync::Arc;
use std::any::Any;

<span class="boring">pub trait Executor {}
</span><span class="boring">pub trait Future { type Item; }
</span>#[allow(clippy::type_complexity)]
pub struct AgentTask&lt;A&gt;(Arc&lt;dyn Fn(&amp;dyn Executor) -&gt; Box&lt;dyn Future&lt;Item=A&gt;&gt; + Send + Sync&gt;);
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="73-combinators"><a class="header" href="#73-combinators">7.3 Combinators</a></h2>
<p>Now we can implement the combinators.</p>
<h3 id="completed_task-unit-and-lazy_task"><a class="header" href="#completed_task-unit-and-lazy_task"><code>completed_task</code> (unit) and <code>lazy_task</code></a></h3>
<p><code>completed_task</code> wraps a value immediately.
<code>lazy_task</code> wraps a computation lazily by combining <code>completed_task</code> and <code>spawn_agent</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::sync::Arc;
</span><span class="boring">pub trait Executor {}
</span><span class="boring">pub trait Future { type Item; }
</span><span class="boring">pub struct UnitFuture&lt;A&gt;(A);
</span><span class="boring">impl&lt;A&gt; Future for UnitFuture&lt;A&gt; { type Item = A; }
</span><span class="boring">pub struct AgentTask&lt;A&gt;(Arc&lt;dyn Fn(&amp;dyn Executor) -&gt; Box&lt;dyn Future&lt;Item=A&gt;&gt; + Send + Sync&gt;);
</span><span class="boring">impl&lt;A&gt; AgentTask&lt;A&gt; { fn new&lt;F&gt;(f: F) -&gt; Self where F: Fn(&amp;dyn Executor) -&gt; Box&lt;dyn Future&lt;Item=A&gt;&gt; + Send + Sync + 'static { AgentTask(Arc::new(f)) } }
</span><span class="boring">fn spawn_agent&lt;A, F&gt;(f: F) -&gt; AgentTask&lt;A&gt; where F: Fn() -&gt; AgentTask&lt;A&gt; { unimplemented!() }
</span>pub fn completed_task&lt;A: Clone + Send + Sync + 'static&gt;(a: A) -&gt; AgentTask&lt;A&gt; {
    AgentTask::new(move |_| Box::new(UnitFuture(a.clone())))
}

pub fn lazy_task&lt;A, F&gt;(a: F) -&gt; AgentTask&lt;A&gt; 
where A: Clone + Send + Sync + 'static, F: Fn() -&gt; A + Send + Sync + 'static + Clone {
    spawn_agent(move || completed_task(a()))
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="join_results-map2"><a class="header" href="#join_results-map2"><code>join_results</code> (map2)</a></h3>
<p><code>join_results</code> is where the magic happens. It combines two parallel agent tasks.</p>
<h3 id="spawn_agent-fork"><a class="header" href="#spawn_agent-fork"><code>spawn_agent</code> (fork)</a></h3>
<p><code>spawn_agent</code> is responsible for shifting execution to a separate worker thread.</p>
<h2 id="74-laws-and-deadlocks"><a class="header" href="#74-laws-and-deadlocks">7.4 Laws and Deadlocks</a></h2>
<p>An important property we expect is:
<code>spawn_agent(x) == x</code></p>
<p>Isolating a task in a sub-agent shouldn't change the result, only <em>where</em> it runs.</p>
<h2 id="75-derived-combinators"><a class="header" href="#75-derived-combinators">7.5 Derived Combinators</a></h2>
<p>Using <code>join_results</code>, <code>completed_task</code>, and <code>spawn_agent</code>, we can derive:</p>
<ul>
<li><code>async_function</code>: Lift a tool <code>A -&gt; B</code> to <code>A -&gt; AgentTask&lt;B&gt;</code>.</li>
<li><code>sequence_tasks</code>: Convert <code>Vec&lt;AgentTask&lt;A&gt;&gt;</code> to <code>AgentTask&lt;Vec&lt;A&gt;&gt;</code>.</li>
<li><code>parallel_filter</code>: Filter a list using a parallel predicate (e.g., "Is this document relevant?").</li>
</ul>
<h3 id="exercise-711-choice-router"><a class="header" href="#exercise-711-choice-router">Exercise 7.11: <code>choice</code> (Router)</a></h3>
<p>We realized we can choose between two tasks based on a boolean condition (e.g. "If tool failed, try fallback").</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span>pub fn router&lt;A&gt;(cond: AgentTask&lt;bool&gt;, t: AgentTask&lt;A&gt;, f: AgentTask&lt;A&gt;) -&gt; AgentTask&lt;A&gt; {
    unimplemented!()
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="exercise-713-flat_map-dynamic-planner"><a class="header" href="#exercise-713-flat_map-dynamic-planner">Exercise 7.13: <code>flat_map</code> (Dynamic Planner)</a></h3>
<p>The most general form of dynamic choice is <code>flat_map</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct AgentTask&lt;A&gt;(A);
</span>pub fn dynamic_planner&lt;A, B, F&gt;(task: AgentTask&lt;A&gt;, next_step: F) -&gt; AgentTask&lt;B&gt;
where F: Fn(A) -&gt; AgentTask&lt;B&gt; {
    unimplemented!()
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>In this chapter, we built a functional Agent Orchestrator. We saw how:</p>
<ol>
<li><strong>Pure descriptions</strong> (<code>AgentTask</code>) separate the "Plan" from the "Runtime".</li>
<li><strong>Strictness in Rust</strong> requires explicit thunks or closures.</li>
<li><strong>Thread safety</strong> in Rust ensures our Agents don't have race conditions.</li>
</ol>
<p>In the next chapter, we will explore <strong>Eval Benchmarks</strong>, where we will use generative testing to verify our Agents behave correctly.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-8-eval-benchmarks-property-based-testing"><a class="header" href="#chapter-8-eval-benchmarks-property-based-testing">Chapter 8: Eval Benchmarks (Property-Based Testing)</a></h1>
<p>In this chapter, we design a library for <strong>Agent Evals</strong>, similar to Property-Based Testing. The goal is to separate the <em>specification</em> of robust agent behavior from the <em>generation</em> of test cases.</p>
<p>Instead of writing individual test scenarios (e.g., "Ask about Paris weather"), we define <strong>Invariants</strong> that should hold for <em>all</em> inputs (e.g., "The response must always be valid JSON" or "The tool call must contain required arguments"). The library then automatically generates random inputs (Mock Prompts) to verify these properties.</p>
<h2 id="81-data-types-for-evals"><a class="header" href="#81-data-types-for-evals">8.1 Data Types for Evals</a></h2>
<p>We need two core data types:</p>
<ol>
<li><strong><code>TestCaseGenerator&lt;A&gt;</code></strong>: A tool that knows how to produce mock inputs of type <code>A</code> (e.g. valid User Queries, malicious prompt injections, etc.).</li>
<li><strong><code>EvalMetric</code></strong>: A property that can be checked, resulting in Pass/Fail.</li>
</ol>
<h3 id="811-generators-testcasegenerator"><a class="header" href="#811-generators-testcasegenerator">8.1.1 Generators (<code>TestCaseGenerator</code>)</a></h3>
<p>A generator is essentially a state transition over a random number generator (MockLLM).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct State&lt;S, A&gt;(Box&lt;dyn Fn(S) -&gt; (A, S)&gt;);
</span><span class="boring">struct SimpleMockLLM;
</span>pub struct TestCaseGenerator&lt;A&gt;(State&lt;SimpleMockLLM, A&gt;);
<span class="boring">fn main() {}</span></code></pre></pre>
<p>This allows us to leverage all the combinators we wrote for <code>Agent&lt;S, A&gt;</code>, like <code>map</code> and <code>flat_map</code>, to compose complex test cases.</p>
<h4 id="primitives"><a class="header" href="#primitives">Primitives</a></h4>
<ul>
<li><strong><code>choose(start, stop)</code></strong>: Generates a random number (token).</li>
<li><strong><code>weighted_boolean(p)</code></strong>: Generates true with probability <code>p</code> (e.g. simulate tool failure).</li>
</ul>
<h4 id="combinators"><a class="header" href="#combinators">Combinators</a></h4>
<ul>
<li><strong><code>list_of_n(n, gen)</code></strong>: Generates a conversation of length <code>n</code>.</li>
<li><strong><code>flat_map</code></strong>: Allows a test case to depend on the output of another (e.g. generate a Tool Call, then generate a valid Output for it).</li>
</ul>
<h3 id="812-properties-evalmetric"><a class="header" href="#812-properties-evalmetric">8.1.2 Properties (<code>EvalMetric</code>)</a></h3>
<p>An eval metric is something we can check. A simple boolean <code>check</code> is insufficient because we want to know <em>why</em> it failed (the specific prompt that broke the agent) and how many tests passed.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">struct MaxSize(i32);
</span><span class="boring">struct TestCases(i32);
</span><span class="boring">struct SimpleMockLLM;
</span><span class="boring">struct FailedCase(String);
</span><span class="boring">struct SuccessCount(i32);
</span>pub struct EvalMetric(Rc&lt;dyn Fn(MaxSize, TestCases, SimpleMockLLM) -&gt; EvalResult&gt;);

pub enum EvalResult {
    Passed,
    Falsified(FailedCase, SuccessCount),
    Proved,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="82-test-case-minimization"><a class="header" href="#82-test-case-minimization">8.2 Test Case Minimization</a></h2>
<p>Debugging agent failures on massive context windows is hard. There are two main approaches:</p>
<ol>
<li><strong>Shrinking</strong>: Find a failure (long context), then iteratively remove messages to look for the root cause.</li>
<li><strong>Sized Generation</strong>: Start with short contexts and gradually increase size.</li>
</ol>
<h2 id="83-example-verifying-jsontool-robustness"><a class="header" href="#83-example-verifying-jsontool-robustness">8.3 Example: Verifying <code>JsonTool</code> Robustness</a></h2>
<p>Let's test if a <code>JsonTool</code> behaves correctly: "For any Valid JSON object, parsing it and then serializing it should yield the original object (semantically)."</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct SGen&lt;A&gt;(A);
</span><span class="boring">impl&lt;A&gt; SGen&lt;A&gt; { fn list_of(g: TestCaseGenerator&lt;A&gt;) -&gt; SGen&lt;Vec&lt;A&gt;&gt; { SGen(Vec::new()) } }
</span><span class="boring">struct TestCaseGenerator&lt;A&gt;(A);
</span><span class="boring">impl&lt;A&gt; TestCaseGenerator&lt;A&gt; { fn choose(start: i32, stop: i32) -&gt; TestCaseGenerator&lt;i32&gt; { TestCaseGenerator(0) } }
</span><span class="boring">struct SimpleMockLLM; impl SimpleMockLLM { fn new(s: i64) -&gt; Self { SimpleMockLLM } }
</span><span class="boring">struct EvalResult; impl EvalResult { fn is_falsified(&amp;self) -&gt; bool { false } }
</span><span class="boring">struct EvalMetric; impl EvalMetric { fn check(&amp;self, a: i32, b: i32, rng: SimpleMockLLM) -&gt; EvalResult { EvalResult } }
</span><span class="boring">fn for_all_sgen&lt;A, F&gt;(g: SGen&lt;A&gt;, f: F) -&gt; EvalMetric where F: Fn(A) -&gt; bool { EvalMetric }
</span>
#[test]
fn test_json_integrity() {
    let small_int = TestCaseGenerator::&lt;i32&gt;::choose(0, 100);
    // Pretend this generates JSON vectors
    let json_prop = for_all_sgen(SGen::list_of(small_int), |data: Vec&lt;i32&gt;| {
        let serialized = format!("{:?}", data);
        // Simulate parsing
        let parsed: Vec&lt;i32&gt; = serialized.trim_matches(|c| c == '[' || c == ']').split(", ").map(|s| s.parse().unwrap_or(0)).collect();
        data == parsed
    });
    
    // Run the eval
    let result = json_prop.check(10, 100, SimpleMockLLM::new(42));
    assert!(!result.is_falsified());
}
<span class="boring">fn main() {} </span></code></pre></pre>
<p>This ensures that for any generated data structure, our "Agent" (Parser) preserves integrity.</p>
<h2 id="85-summary"><a class="header" href="#85-summary">8.5 Summary</a></h2>
<p>We have built a powerful Eval framework. It demonstrates how functional design principles apply to verifying Agent behavior.</p>
<h2 id="86-references"><a class="header" href="#86-references">8.6 References</a></h2>
<ul>
<li><strong>Rust Book Ch 11 (Testing)</strong>: <a href="https://doc.rust-lang.org/book/ch11-00-testing.html">The Rust Programming Language</a></li>
<li><strong>Rust By Example (Testing)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/testing.html">Testing</a></li>
<li><strong>Proptest (Crate)</strong>: <a href="https://altsysrq.github.io/proptest-book/intro.html">Official Book</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-9-structured-output-parsing-parser-combinators"><a class="header" href="#chapter-9-structured-output-parsing-parser-combinators">Chapter 9: Structured Output Parsing (Parser Combinators)</a></h1>
<p>In this chapter, we explore the design of a <strong>Structured Output Extractor</strong> library. We'll use <strong>JSON Parsing</strong> as our motivating use case—specifically, extracting valid JSON from the often messy output of an LLM.</p>
<p>We will adopt an <strong>algebraic design</strong> approach. Instead of thinking about the internal regexes first, we will start by designing the interface (the algebra)—the types and combinators we need to reliably parse Tool Calls and Structured Data.</p>
<h2 id="91-designing-an-algebra"><a class="header" href="#91-designing-an-algebra">9.1 Designing an Algebra</a></h2>
<p>An <code>Extractor</code> is a program that takes unstructured input (LLM text response) and produces a structured output (like a <code>ToolCall</code> struct). In a combinator library, we build complex extractors by composing simpler ones.</p>
<p>Let's start with the basics. We need a type <code>Extractor&lt;A&gt;</code> representing a parser that produces a value of type <code>A</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct ParseError;
</span>pub trait Extractor&lt;A&gt; {
    fn extract(&amp;self, input: &amp;str) -&gt; Result&lt;A, ParseError&gt;;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>(Note: In our final implementation, <code>Extractor</code> will be a struct wrapping a closure.)</p>
<h3 id="basic-primitives"><a class="header" href="#basic-primitives">Basic Primitives</a></h3>
<p>To parse a specific token (e.g. "json"):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct Extractor&lt;A&gt;(A);
</span>pub fn token(s: String) -&gt; Extractor&lt;String&gt; { Extractor(s) }
<span class="boring">fn main() {}</span></code></pre></pre>
<p>To combine parsers, we need an "or" combinator (Fallback strategy):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct Extractor&lt;A&gt;(A);
</span>pub fn or&lt;A&gt;(p1: Extractor&lt;A&gt;, p2: Extractor&lt;A&gt;) -&gt; Extractor&lt;A&gt; { p1 }
<span class="boring">fn main() {}</span></code></pre></pre>
<p>If <code>p1</code> fails (e.g. Model didn't use markdown code blocks), we try <code>p2</code> (e.g. Raw JSON).</p>
<p>To handle repetition (e.g. Multiple Tool Calls), we need <code>many</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct Extractor&lt;A&gt;(A);
</span>pub fn many&lt;A&gt;(p: Extractor&lt;A&gt;) -&gt; Extractor&lt;Vec&lt;A&gt;&gt; { Extractor(vec![]) }
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="context-sensitivity-and-flat_map"><a class="header" href="#context-sensitivity-and-flat_map">Context Sensitivity and <code>flat_map</code></a></h3>
<p>Some parsing tasks require <strong>context sensitivity</strong>, where the next parser depends on the result of the previous one. For example, extracting a specific field based on a previously parsed "tool_name".</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct Extractor&lt;A&gt;(A);
</span>pub fn flat_map&lt;A, B, F&gt;(p: Extractor&lt;A&gt;, f: F) -&gt; Extractor&lt;B&gt; where F: Fn(A) -&gt; Extractor&lt;B&gt; { f(p.0) }
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="92-implementation"><a class="header" href="#92-implementation">9.2 Implementation</a></h2>
<p>Purely functional parser combinators in Rust are elegantly implemented using <strong>functions</strong> (closures).</p>
<h3 id="the-extractor-type"><a class="header" href="#the-extractor-type">The Extractor Type</a></h3>
<p>An <code>Extractor&lt;A&gt;</code> acts as a function <code>Fn(&amp;Location) -&gt; Result&lt;(A, Location), ParseError&gt;</code>.</p>
<pre><pre class="playground"><code class="language-rust">use std::rc::Rc;

#[derive(Clone)]
#[allow(clippy::type_complexity)]
pub struct Extractor&lt;A&gt;(Rc&lt;dyn Fn(&amp;Location) -&gt; Result&lt;(A, Location), ParseError&gt;&gt;);
<span class="boring">struct Location;
</span><span class="boring">struct ParseError;
</span><span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="location-and-error-handling"><a class="header" href="#location-and-error-handling">Location and Error Handling</a></h3>
<p>To provide good error messages (for "Refusal" or "Retry" prompts), we track the <code>Location</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span>#[derive(Debug, Clone, PartialEq)]
pub struct Location {
    pub input: Rc&lt;String&gt;,
    pub offset: usize,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>A <code>ParseError</code> contains a stack of errors, allowing us to feed this back to the LLM: "Error parsing JSON at index 45: expected ':'".</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Debug, Clone, PartialEq)] struct Location { input: Rc&lt;String&gt;, offset: usize }
</span>#[derive(Debug, Clone, PartialEq)]
pub struct ParseError {
    pub stack: Vec&lt;(Location, String)&gt;,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="combinators-1"><a class="header" href="#combinators-1">Combinators</a></h3>
<p>The implementation of <code>token</code> checks if the input at the current location starts with the target string.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::rc::Rc;
</span><span class="boring">#[derive(Debug, Clone, PartialEq)] struct Location { input: Rc&lt;String&gt;, offset: usize }
</span><span class="boring">impl Location { fn new(input: Rc&lt;String&gt;, offset: usize) -&gt; Self { Location { input, offset } } }
</span><span class="boring">#[derive(Debug, Clone, PartialEq)] struct ParseError { stack: Vec&lt;(Location, String)&gt; }
</span><span class="boring">impl ParseError { fn new(loc: Location, msg: String) -&gt; Self { ParseError { stack: vec![(loc, msg)] } } }
</span><span class="boring">struct Extractor&lt;A&gt;(Rc&lt;dyn Fn(&amp;Location) -&gt; Result&lt;(A, Location), ParseError&gt;&gt;);
</span><span class="boring">impl&lt;A&gt; Extractor&lt;A&gt; { fn new&lt;F&gt;(f: F) -&gt; Self where F: Fn(&amp;Location) -&gt; Result&lt;(A, Location), ParseError&gt; + 'static { Extractor(Rc::new(f)) } }
</span>pub fn token(s: String) -&gt; Extractor&lt;String&gt; {
    Extractor::new(move |loc: &amp;Location| {
        let input_slice = &amp;loc.input[loc.offset..];
        if input_slice.starts_with(&amp;s) {
            Ok((s.clone(), Location::new(loc.input.clone(), loc.offset + s.len())))
        } else {
            Err(ParseError::new(loc.clone(), format!("Expected '{}'", s)))
        }
    })
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="93-parsing-json-from-llm-output"><a class="header" href="#93-parsing-json-from-llm-output">9.3 Parsing JSON from LLM Output</a></h2>
<p>Most LLMs return JSON, but often wrapped in text. We need an extractor that can <code>skip_until</code> the first <code>{</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">use std::collections::HashMap;
</span>pub enum JSON {
    JNull,
    JBool(bool),
    JNumber(f64),
    JString(String),
    JArray(Vec&lt;JSON&gt;),
    JObject(HashMap&lt;String, JSON&gt;),
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="94-conclusion"><a class="header" href="#94-conclusion">9.4 Conclusion</a></h2>
<p>In this chapter, we saw how algebraic design leads us to a flexible Extractor library. By focusing on primitives like <code>flat_map</code> and <code>or</code>, we can robustly handle the unpredictability of LLM textual output.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-10-map-reduce-summarization-monoids"><a class="header" href="#chapter-10-map-reduce-summarization-monoids">Chapter 10: Map-Reduce Summarization (Monoids)</a></h1>
<p>In this chapter, we explore one of the simplest and most ubiquitous algebraic structures: the <strong>Summarizer</strong> (Monoid). This serves as our introduction to purely algebraic structures.</p>
<p>In Agent systems, we often need to <strong>aggregate</strong> data from multiple sources:</p>
<ul>
<li>Merging conversation histories.</li>
<li>Summing total token usage across parallel agents.</li>
<li>Coalescing partial JSON objects.</li>
</ul>
<h2 id="101-what-is-a-summarizer"><a class="header" href="#101-what-is-a-summarizer">10.1 What is a Summarizer?</a></h2>
<p>A Monoid (Summarizer) consists of:</p>
<ol>
<li>A type <code>A</code>.</li>
<li>An associative binary operation <code>combine(a1, a2): A</code>. (Merging 2 histories).</li>
<li>An identity element <code>empty: A</code>. (Empty history).</li>
</ol>
<pre><pre class="playground"><code class="language-rust">pub trait Summarizer&lt;A&gt; {
    fn combine(&amp;self, a1: A, a2: A) -&gt; A;
    fn empty(&amp;self) -&gt; A;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="examples"><a class="header" href="#examples">Examples</a></h3>
<p><strong>String Concatenation (History Merge)</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Summarizer&lt;A&gt; { fn combine(&amp;self, a1: A, a2: A) -&gt; A; fn empty(&amp;self) -&gt; A; }
</span>pub struct HistoryMerger;
impl Summarizer&lt;String&gt; for HistoryMerger {
    fn combine(&amp;self, a1: String, a2: String) -&gt; String { a1 + &amp;a2 }
    fn empty(&amp;self) -&gt; String { "".to_string() }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p><strong>Token Usage (Int Addition)</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Summarizer&lt;A&gt; { fn combine(&amp;self, a1: A, a2: A) -&gt; A; fn empty(&amp;self) -&gt; A; }
</span>pub struct TokenTotal;
impl Summarizer&lt;i32&gt; for TokenTotal {
    fn combine(&amp;self, a1: i32, a2: i32) -&gt; i32 { a1 + a2 }
    fn empty(&amp;self) -&gt; i32 { 0 }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="102-parallel-summarization-map-reduce"><a class="header" href="#102-parallel-summarization-map-reduce">10.2 Parallel Summarization (Map-Reduce)</a></h2>
<p>If we have a huge context window <code>[Message1, Message2, ...]</code>, we can measure its token cost in parallel by splitting it.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Summarizer&lt;A&gt; { fn combine(&amp;self, a1: A, a2: A) -&gt; A; fn empty(&amp;self) -&gt; A; }
</span>pub fn parallel_summarize&lt;A, B, M, F&gt;(v: &amp;[A], m: &amp;M, f: &amp;F) -&gt; B
where M: Summarizer&lt;B&gt;, F: Fn(&amp;A) -&gt; B + Clone, B: Clone {
    if v.is_empty() {
        m.empty()
    } else if v.len() == 1 {
        f(&amp;v[0])
    } else {
        let (left, right) = v.split_at(v.len() / 2);
        let lb = parallel_summarize(left, m, f);
        let rb = parallel_summarize(right, m, f);
        m.combine(lb, rb)
    }
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="104-example-token-counting-word-count"><a class="header" href="#104-example-token-counting-word-count">10.4 Example: Token Counting (Word Count)</a></h2>
<p>A practical use case is counting tokens in a large corpus without encoding everything sequentially.</p>
<pre><pre class="playground"><code class="language-rust">pub enum TokenStats {
    Fragment(String), // Partial token
    Count(String, i32, String), // (Left partial, count of full tokens, Right partial)
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="105-conclusion"><a class="header" href="#105-conclusion">10.5 Conclusion</a></h2>
<p>Summarizers (Monoids) provide a simple abstraction for parallel aggregation. This sets the stage for more complex algebraic structures like <strong>Generic Agents</strong> (Functors and Monads), which we will explore in the next chapters.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-11-chains-of-thought-monads"><a class="header" href="#chapter-11-chains-of-thought-monads">Chapter 11: Chains of Thought (Monads)</a></h1>
<p>In this chapter, we generalize the patterns we've seen in <code>TestCaseGenerator</code> (Gen), <code>Extractor</code> (Parser), <code>Option</code>, and <code>Agent</code> (State). We identify two key abstractions for Agentic Flow Control: the <strong>Functor</strong> (Mapping) and the <strong>Monad</strong> (Chaining).</p>
<p>In LLM engineering, the <strong>Chain of Thought</strong> (CoT) pattern is ubiquitous. An agent thinks <code>A</code>, then uses <code>A</code> to think <code>B</code>. This dependency (<code>A -&gt; B</code>) is exactly what a Monad captures.</p>
<h2 id="111-functors-mapping-thoughts"><a class="header" href="#111-functors-mapping-thoughts">11.1 Functors (Mapping Thoughts)</a></h2>
<p>A Functor is a type <code>F</code> that provides a <code>map</code> function. E.g., <code>Option::map</code> transforms a potential value without handling the "None" case explicitly.</p>
<p>To work around Rust's lack of Higher-Kinded Types (HKTs), we use <strong>Generic Associated Types (GATs)</strong>.</p>
<pre><pre class="playground"><code class="language-rust">pub trait Functor {
    type Wrapped&lt;A&gt;;
    
    fn map&lt;A, B, F&gt;(fa: Self::Wrapped&lt;A&gt;, f: F) -&gt; Self::Wrapped&lt;B&gt; 
    where F: Fn(A) -&gt; B;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="112-monads-reasoning-chains"><a class="header" href="#112-monads-reasoning-chains">11.2 Monads (Reasoning Chains)</a></h2>
<p>The Monad abstraction adds <code>unit</code> (Thought) and <code>flat_map</code> (Next Step).
In Agent terms, <code>flat_map</code> allows the <em>next step</em> of the chain to be determined by the <em>result</em> of the previous step.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Functor { type Wrapped&lt;A&gt;; fn map&lt;A, B, F&gt;(fa: Self::Wrapped&lt;A&gt;, f: F) -&gt; Self::Wrapped&lt;B&gt; where F: Fn(A) -&gt; B; }
</span>pub trait Monad: Functor {
    fn unit&lt;A&gt;(a: A) -&gt; Self::Wrapped&lt;A&gt;;
    
    fn flat_map&lt;A, B, F&gt;(ma: Self::Wrapped&lt;A&gt;, f: F) -&gt; Self::Wrapped&lt;B&gt;
    where F: Fn(A) -&gt; Self::Wrapped&lt;B&gt;;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="113-instances"><a class="header" href="#113-instances">11.3 Instances</a></h2>
<p>We can implement Monad instances for:</p>
<ul>
<li><strong>Option (Validation)</strong>: Simple sequencing. Failure short-circuits the reasoning chain.</li>
<li><strong>Vec (Branching)</strong>: Represents non-determinism (Generating multiple hypotheses). <code>flat_map</code> explores all branches.</li>
<li><strong>Id (Direct)</strong>: The identity monad.</li>
<li><strong>Agent (State)</strong>: The "Agent Monad" from Chapter 6. <code>flat_map</code> sequences actions while passing memory.</li>
</ul>
<h2 id="114-combinators"><a class="header" href="#114-combinators">11.4 Combinators</a></h2>
<p>Once we have the <code>Monad</code> trait, we can define powerful combinators that work for <em>any</em> reasoning chain:</p>
<ul>
<li><strong><code>sequence</code></strong>: Turns a list of steps <code>Vec&lt;Step&lt;A&gt;&gt;</code> into a single Step yielding a list <code>Step&lt;Vec&lt;A&gt;&gt;</code>.</li>
<li><strong><code>filterM</code></strong>: Filters a list based on a reasoning predicate (e.g. "Keep only relevant documents").</li>
</ul>
<h2 id="115-conclusion"><a class="header" href="#115-conclusion">11.5 Conclusion</a></h2>
<p>Monads provide a unified interface for sequencing operations. They are the mathematical foundation of "Chain of Thought" prompting.</p>
<h2 id="116-references"><a class="header" href="#116-references">11.6 References</a></h2>
<ul>
<li><strong>Rust Blog (GATs)</strong>: <a href="https://blog.rust-lang.org/2022/10/28/gats-stabilization.html">Stabilization Announcement</a></li>
<li><strong>Rust By Example (Traits)</strong>: <a href="https://doc.rust-lang.org/rust-by-example/trait.html">Traits</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-12-parallel-queries-applicative-and-traversable"><a class="header" href="#chapter-12-parallel-queries-applicative-and-traversable">Chapter 12: Parallel Queries (Applicative and Traversable)</a></h1>
<p>In this chapter, we discover that <strong>Reasoning Chain</strong> (Monad) is not the only useful abstraction for Agentic computation. We introduce <strong>Parallel Executor</strong> (Applicative), which allows for different behaviors, such as parallel tool execution and error accumulation. We then generalize the <code>traverse</code> and <code>sequence</code> functions into the <strong>Batch Executor</strong> (Traverse) trait.</p>
<h2 id="121-parallel-executors-applicatives"><a class="header" href="#121-parallel-executors-applicatives">12.1 Parallel Executors (Applicatives)</a></h2>
<p>A Reasoning Chain (Monad) is defined by <code>unit</code> and <code>flat_map</code> (sequential).
A Parallel Executor (Applicative) is defined by <code>unit</code> and <code>map2</code> (parallel).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Functor { type Wrapped&lt;A&gt;; fn map&lt;A, B, F&gt;(fa: Self::Wrapped&lt;A&gt;, f: F) -&gt; Self::Wrapped&lt;B&gt; where F: Fn(A) -&gt; B; }
</span>pub trait Applicative: Functor {
    fn unit&lt;A&gt;(a: A) -&gt; Self::Wrapped&lt;A&gt;;
    
    fn map2&lt;A, B, C, F&gt;(
        fa: Self::Wrapped&lt;A&gt;,
        fb: Self::Wrapped&lt;B&gt;,
        f: F
    ) -&gt; Self::Wrapped&lt;C&gt;;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="why-applicative"><a class="header" href="#why-applicative">Why Applicative?</a></h3>
<p>If we look at <code>map2</code> vs <code>flat_map</code>:</p>
<ul>
<li><code>flat_map</code> allows the <em>structure</em> of the second thought to depend on the <em>result</em> of the first. "If tool A returns X, call tool B. Else call C."</li>
<li><code>map2</code> takes two independent tasks and combines their results. "Call tool A and tool B."</li>
</ul>
<p>This independence means:</p>
<ol>
<li><strong>Parallelism</strong>: Since <code>fa</code> and <code>fb</code> are independent, they can be computed in parallel.</li>
<li><strong>Analysis</strong>: We can inspect the structure of the computation plan without running it.</li>
</ol>
<h2 id="122-batch-executor-traverse"><a class="header" href="#122-batch-executor-traverse">12.2 Batch Executor (Traverse)</a></h2>
<p>We've seen <code>batch_execute</code> (traverse) for Lists and Options. We can abstract this into a <strong>Traverse</strong> trait.</p>
<p>A Traversable functor allows us to iterate over a data structure (like a <code>ConversationTree</code>) while maintaining an effect (Parallel Execution) context.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">pub trait Functor { type Wrapped&lt;A&gt;; fn map&lt;A, B, F&gt;(fa: Self::Wrapped&lt;A&gt;, f: F) -&gt; Self::Wrapped&lt;B&gt; where F: Fn(A) -&gt; B; }
</span><span class="boring">pub trait Applicative: Functor { fn unit&lt;A&gt;(a: A) -&gt; Self::Wrapped&lt;A&gt;; fn map2&lt;A, B, C, F&gt;(fa: Self::Wrapped&lt;A&gt;, fb: Self::Wrapped&lt;B&gt;, f: F) -&gt; Self::Wrapped&lt;C&gt;; }
</span>pub trait Traverse: Functor {
    fn traverse&lt;G, A, B, F&gt;(
        fa: Self::Wrapped&lt;A&gt;,
        f: F
    ) -&gt; G::Wrapped&lt;Self::Wrapped&lt;B&gt;&gt;
    where G: Applicative;
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="123-conclusion"><a class="header" href="#123-conclusion">12.3 Conclusion</a></h2>
<p>Applicative and Traversable allow us to separate the <em>mechanism</em> of execution (Sequential vs Parallel) from the <em>structure</em> of the data (List vs Tree).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-13-tool-use-external-io"><a class="header" href="#chapter-13-tool-use-external-io">Chapter 13: Tool Use (External I/O)</a></h1>
<p>This chapter explores how to handle <strong>External Tools</strong> (like reading files, searching the web, or calling APIs) in a purely functional way. The core idea is to separate the <strong>description</strong> of the tool call (<code>ToolAction</code>) from its <strong>execution</strong>.</p>
<blockquote>
<p>[!NOTE]
In idiomatic Rust, I/O is typically handled imperatively with <code>std::io</code> or asynchronously with <code>Future</code>. This chapter explores the <em>pure functional modeling</em> of Tool Use, which powers the design of Agent Runtimes.</p>
</blockquote>
<h2 id="131-the-toolaction-type"><a class="header" href="#131-the-toolaction-type">13.1 The ToolAction Type</a></h2>
<p>We can model an effectful tool call as a value that, when "run", performs the effect.</p>
<pre><pre class="playground"><code class="language-rust">pub struct ToolAction&lt;A&gt;(Box&lt;dyn FnOnce() -&gt; A&gt;);

impl&lt;A: 'static&gt; ToolAction&lt;A&gt; {
    pub fn new&lt;F&gt;(f: F) -&gt; Self where F: FnOnce() -&gt; A + 'static { 
        ToolAction(Box::new(f)) 
    }
    
    pub fn execute(self) -&gt; A { (self.0)() }
    
    pub fn then_act&lt;B: 'static, F&gt;(self, f: F) -&gt; ToolAction&lt;B&gt;
    where F: FnOnce(A) -&gt; ToolAction&lt;B&gt; + 'static
    {
        ToolAction::new(move || f(self.execute()).execute())
    }
}
<span class="boring">fn main() {
</span><span class="boring">    let action = ToolAction::new(|| 42);
</span><span class="boring">    assert_eq!(action.execute(), 42);
</span><span class="boring">}</span></code></pre></pre>
<h2 id="132-composition"><a class="header" href="#132-composition">13.2 Composition</a></h2>
<p>Since <code>ToolAction</code> is a description, we can compose these descriptions. <code>ToolAction</code> forms a Monad.</p>
<ul>
<li><strong><code>map</code></strong>: Transform the result (e.g., parse tool output).</li>
<li><strong><code>then_act</code> (flat_map)</strong>: Chain tools, where the second tool depends on the result of the first.</li>
</ul>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct ToolAction&lt;A&gt;(Box&lt;dyn FnOnce() -&gt; A&gt;);
</span><span class="boring">impl&lt;A: 'static&gt; ToolAction&lt;A&gt; {
</span><span class="boring">    fn new&lt;F&gt;(f: F) -&gt; Self where F: FnOnce() -&gt; A + 'static { ToolAction(Box::new(f)) }
</span><span class="boring">    fn execute(self) -&gt; A { (self.0)() }
</span><span class="boring">    fn then_act&lt;B: 'static, F&gt;(self, f: F) -&gt; ToolAction&lt;B&gt; where F: FnOnce(A) -&gt; ToolAction&lt;B&gt; + 'static {
</span><span class="boring">        ToolAction::new(move || f((self.0)()).execute())
</span><span class="boring">    }
</span><span class="boring">}
</span>struct Terminal;
impl Terminal {
    fn read_user_input() -&gt; ToolAction&lt;String&gt; { ToolAction::new(|| "User query".to_string()) }
    fn emit_log(msg: &amp;str) -&gt; ToolAction&lt;()&gt; { ToolAction::new(|| ()) }
}

let agent_loop = Terminal::read_user_input()
    .then_act(|query| Terminal::emit_log(&amp;format!("Processing: {}", query)));
<span class="boring">fn main() {}</span></code></pre></pre>
<p>Until we call <code>agent_loop.execute()</code>, nothing happens. This is <strong>Referential Transparency</strong>: the expression <code>agent_loop</code> can be replaced by its definition without changing the outcome (because the outcome <em>is just a description</em>, not the side effect itself).</p>
<h2 id="133-limitations-and-the-free-monad"><a class="header" href="#133-limitations-and-the-free-monad">13.3 Limitations and The Free Monad</a></h2>
<p>Our simple <code>ToolAction</code> uses the Rust call stack. Deeply recursive loops (infinite agents) will overflow.
We solve this using <strong>Trampolining</strong> or the <strong>Free Monad</strong> (Data as Control Flow).</p>
<h2 id="134-use-cases"><a class="header" href="#134-use-cases">13.4 Use Cases</a></h2>
<p>This pattern allows us to:</p>
<ol>
<li><strong>Test Agents</strong>: We can swap the "Interpreter" to mock tools without changing the Agent's logic.</li>
<li><strong>Safe Refactoring</strong>: We can refactor effectful sequences with confidence.</li>
<li><strong>Audit Logs</strong>: We can inspect the <code>ToolAction</code> before running it to ensure safety/alignment.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-14-scratchpads-local-effects"><a class="header" href="#chapter-14-scratchpads-local-effects">Chapter 14: Scratchpads (Local Effects)</a></h1>
<p>In Agentic programming, we maintain purity in our interfaces ("Input -&gt; Output"). However, some internal reasoning steps (like sorting evidence, accumulating stats, or graph search) are naturally expressed with mutable state. The types <code>Scratchpad</code> (ST) and <code>ScratchRef</code> allow an Agent to use mutable memory <em>locally</em> while remaining externally pure.</p>
<h2 id="141-purely-functional-in-place-reasoning"><a class="header" href="#141-purely-functional-in-place-reasoning">14.1 Purely Functional In-Place Reasoning?</a></h2>
<p>It sounds like a contradiction. How can we have mutation in a pure function?
The key is <strong>Scope</strong>.
If an Agent allocates a mutable "Scratchpad", scribbles on it, and then returns a frozen summary, and <em>no one else</em> ever saw the scratchpad, then the Agent appears pure from the outside.</p>
<h2 id="142-the-scratchpad-monad"><a class="header" href="#142-the-scratchpad-monad">14.2 The Scratchpad Monad</a></h2>
<p>We implemented <code>Scratchpad&lt;'a, A&gt;</code> where <code>'a</code> represents the "thread" or scope of the scratchpad.</p>
<pre><pre class="playground"><code class="language-rust">pub struct Scratchpad&lt;'a, A&gt; {
    run: Box&lt;dyn FnOnce() -&gt; A + 'a&gt;, // Closure capturing mutable 'a references
}
<span class="boring">fn main() {}</span></code></pre></pre>
<h3 id="preventing-leakage-data-privacy"><a class="header" href="#preventing-leakage-data-privacy">Preventing Leakage (Data Privacy)</a></h3>
<p>The danger is leaking a mutable reference to the global scope (Hallucinating internal state into the final answer).
Rust's Higher-Rank Trait Bounds (HRTB) prevent this leakage. The phantom lifetime <code>'a</code> ensures that <code>ScratchRef</code> cannot escape the <code>run_scratchpad</code> block.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">struct ScratchRef&lt;'a, T&gt;(std::marker::PhantomData&lt;&amp;'a T&gt;);
</span><span class="boring">impl&lt;'a, T&gt; ScratchRef&lt;'a, T&gt; { fn new(_: T) -&gt; Self { ScratchRef(std::marker::PhantomData) } }
</span><span class="boring">struct Scratchpad&lt;'a, A&gt;(std::marker::PhantomData&lt;&amp;'a A&gt;);
</span><span class="boring">fn run_scratchpad&lt;A, T&gt;(_: ScratchRef&lt;'_, T&gt;) { }
</span>// let leaking_ref = run_scratchpad(ScratchRef::new(1)); // ERROR! Result cannot be ScratchRef
<span class="boring">fn main() {}</span></code></pre></pre>
<h2 id="143-comparison-with-rust-references"><a class="header" href="#143-comparison-with-rust-references">14.3 Comparison with Rust References</a></h2>
<p>In a sense, <strong>Rust is the Scratchpad Monad</strong>. Every block of code with local variables is an implicit <code>Scratchpad</code> computation. However, the explicit <code>Scratchpad</code> monad is useful when we want to treat "stateful reasoning" as First-Class Values.</p>
<h2 id="144-conclusion"><a class="header" href="#144-conclusion">14.4 Conclusion</a></h2>
<p>We now have the ability to write efficient, in-place algorithms (like "Evidence Sorting") using the <code>Scratchpad</code> monad, wrapping them safely so they appear pure to the rest of the orchestration system.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-15-streaming-pipelines"><a class="header" href="#chapter-15-streaming-pipelines">Chapter 15: Streaming Pipelines</a></h1>
<p>The final step in our journey is to handle I/O incrementally. We want to process data (like streams of tokens from an LLM) without loading everything into memory, but still retain the composability of <code>map</code>, <code>filter</code>, and <code>fold</code>.</p>
<h2 id="151-the-problem-with-llm-streams"><a class="header" href="#151-the-problem-with-llm-streams">15.1 The Problem with LLM Streams</a></h2>
<p>Standard imperative loops mix the <em>logic</em> (what to detect) with the <em>mechanics</em> (how to buffer tokens).
Standard functional <code>List</code> requires waiting for the full response (high latency).</p>
<h2 id="152-the-pipeline-algebra"><a class="header" href="#152-the-pipeline-algebra">15.2 The Pipeline Algebra</a></h2>
<p>We define <code>Pipeline&lt;I, O&gt;</code> as a state machine that can:</p>
<ol>
<li><strong>YieldEvent</strong> a value of type <code>O</code>.</li>
<li><strong>AwaitInput</strong> of type <code>I</code>.</li>
<li><strong>Halt</strong>.</li>
</ol>
<pre><pre class="playground"><code class="language-rust">pub enum Pipeline&lt;I, O&gt; {
    YieldEvent(O, Box&lt;Pipeline&lt;I, O&gt;&gt;),
    AwaitInput(Box&lt;dyn FnOnce(Option&lt;I&gt;) -&gt; Pipeline&lt;I, O&gt;&gt;),
    Halt,
}
<span class="boring">fn main() {}</span></code></pre></pre>
<p>This is a <strong>Pull-based</strong> stream. The driver calls the pipeline; if it yields, we show the token. If it awaits, we fetch the next token from the API.</p>
<h2 id="153-composition-the-pipe-"><a class="header" href="#153-composition-the-pipe-">15.3 Composition: The Pipe (<code>|&gt;</code>)</a></h2>
<p>The true power comes from <code>pipe</code>. We can feed the output of one pipeline (e.g. <code>Tokenizer</code>) into the input of another (e.g. <code>StopSequenceDetector</code>).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">enum Pipeline&lt;I, O&gt; { YieldEvent(O, Box&lt;Pipeline&lt;I, O&gt;&gt;), AwaitInput(Box&lt;dyn FnOnce(Option&lt;I&gt;) -&gt; Pipeline&lt;I, O&gt;&gt;), Halt }
</span><span class="boring">impl&lt;I, O&gt; Pipeline&lt;I, O&gt; {
</span><span class="boring">    fn filter&lt;F&gt;(_: F) -&gt; Pipeline&lt;I, I&gt; where F: Fn(&amp;I) -&gt; bool { Pipeline::Halt }
</span><span class="boring">    fn lift&lt;F&gt;(_: F) -&gt; Pipeline&lt;I, O&gt; where F: Fn(I) -&gt; O { Pipeline::Halt }
</span><span class="boring">    fn pipe&lt;O2&gt;(self, _: Pipeline&lt;O, O2&gt;) -&gt; Pipeline&lt;I, O2&gt; { Pipeline::Halt }
</span><span class="boring">}
</span>let p1 = Pipeline::&lt;i32, i32&gt;::filter(|token_id| *token_id != 0); // Filter padding
let p2 = Pipeline::&lt;i32, i32&gt;::lift(|x| x); // Pass through
let pipeline = p1.pipe(p2); // Fused Pipeline
<span class="boring">fn main() {}</span></code></pre></pre>
<p>The <code>pipe</code> implementation fuses the two machines into one. It ensures <strong>constant memory usage</strong> (processing one token at a time).</p>
<h2 id="154-conclusion"><a class="header" href="#154-conclusion">15.4 Conclusion</a></h2>
<p>This architecture is the foundation of modern Agentic streaming libraries. It allows us to process infinite streams of reasoning or massive context contexts with elegance.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
